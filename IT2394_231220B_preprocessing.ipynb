{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe7568d-1773-405c-8a3a-a0822a7db1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text preprocessing libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import string\n",
    "\n",
    "# Feature extraction libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49df07d",
   "metadata": {},
   "source": [
    "# Text Feature Engineering - BG3 Reviews Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates comprehensive text preprocessing and feature engineering techniques on the BG3 reviews dataset. We will convert unstructured text into meaningful numerical features suitable for machine learning analysis.\n",
    "\n",
    "### Key Learning Objectives:\n",
    "1. **Terminology**: Understand Corpus, Bag of Words, Document, Term, and Vocabulary\n",
    "2. **Count Vectorizer**: Convert text documents to token count matrices\n",
    "3. **TF-IDF Vectorizer**: Implement term frequency-inverse document frequency weighting\n",
    "4. **Text Similarity**: Apply cosine similarity to compare documents\n",
    "5. **Preprocessing Pipeline**: Implement comprehensive text cleaning and normalization\n",
    "\n",
    "### Components to Cover:\n",
    "- Tokenization by unigrams\n",
    "- Case conversion to lowercase\n",
    "- Remove punctuations\n",
    "- Lemmatization\n",
    "- Remove stop words\n",
    "- Strip special characters and noises\n",
    "- Remove spelling errors\n",
    "- Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2bb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33772, 3)\n",
      "\n",
      "First few rows:\n",
      "                                                text          date source\n",
      "0  I cannot recommend this game enough. Larian ha...  Apr 21, 2025  steam\n",
      "1  A game I can just sit and play for hours, ever...  Nov 25, 2025  steam\n",
      "2  Great game hard to figure out the cam and thin...  May 02, 2025  steam\n",
      "3  Apparently, I am playing this game of reviewin...  Nov 16, 2025  steam\n",
      "4  Like the extensive story line, characters are ...  Nov 14, 2025  steam\n",
      "\n",
      "Column names:\n",
      "['text', 'date', 'source']\n",
      "\n",
      "Data types:\n",
      "text      str\n",
      "date      str\n",
      "source    str\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "text      0\n",
      "date      0\n",
      "source    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('bg3_reviews_train.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898c1f1",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing Pipeline\n",
    "\n",
    "We will implement a comprehensive text preprocessing function that applies all cleaning techniques in the correct order:\n",
    "1. Expand contractions (e.g., \"don't\" \u2192 \"do not\")\n",
    "2. Convert to lowercase\n",
    "3. Remove URLs and special patterns\n",
    "4. Tokenize into unigrams\n",
    "5. Remove punctuation\n",
    "6. Remove stop words\n",
    "7. Lemmatize words\n",
    "8. Remove spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14173ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I can't believe it's not working. They've done it!\n",
      "After contraction expansion: i cannot believe it is not working. they have done it!\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for expanding common contractions\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"\n",
    "    Expand contractions in the text (e.g., don't -> do not)\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
    "    return pattern.sub(lambda x: contractions_dict[x.group()], text.lower())\n",
    "\n",
    "# Test contraction expansion\n",
    "test_text = \"I can't believe it's not working. They've done it!\"\n",
    "print(\"Original:\", test_text)\n",
    "print(\"After contraction expansion:\", expand_contractions(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10f44a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I can't believe how amazing this game is! The graphics are absolutely stunning & the gameplay is very engaging. However, there r some bugs that need fixing. Don't worry, it's still the best RPG ever! #BG3 #DnD\n",
      "\n",
      "Cleaned text:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['believe', 'amaze', 'game', 'graphic', 'absolutely', 'stun', 'gameplay', 'engage', 'however', 'bug', 'need', 'fix', 'worry', 'still', 'best', 'rpg', 'ever', 'bg3', 'dnd']\n"
     ]
    }
   ],
   "source": [
    "# Initialize lemmatizer and stop words\nlemmatizer = WordNetLemmatizer()\nstop_words = set(stopwords.words('english'))\n\ndef simple_spell_check(word, dictionary):\n    \"\"\"\n    Simple spell checking using edit distance\n    Returns the closest word in dictionary if edit distance <= 1\n    \"\"\"\n    if word in dictionary:\n        return word\n    \n    # Find words with edit distance of 1\n    candidates = [w for w in dictionary if edit_distance(word, w) == 1]\n    \n    if candidates:\n        return candidates[0]\n    return word\n\n# Create a dictionary of common English words for spell checking\ncommon_words = set(stopwords.words('english'))\n# Add more vocabulary\ncommon_words.update(['game', 'good', 'bad', 'love', 'hate', 'great', 'amazing', \n                     'beautiful', 'terrible', 'excellent', 'poor', 'wonderful'])\n\ndef preprocess_text(text):\n    \"\"\"\n    Comprehensive text preprocessing pipeline\n    \n    Steps:\n    1. Expand contractions\n    2. Convert to lowercase (included in expand_contractions)\n    3. Remove URLs and emails\n    4. Remove special characters and extra whitespace\n    5. Tokenize by unigrams\n    6. Remove punctuation\n    7. Remove stop words\n    8. Lemmatization\n    9. Simple spell correction\n    \n    Args:\n        text (str): Raw text to preprocess\n        \n    Returns:\n        list: List of cleaned and processed tokens\n    \"\"\"\n    \n    # Handle missing values\n    if not isinstance(text, str):\n        return []\n    \n    # Step 1-2: Expand contractions and convert to lowercase\n    text = expand_contractions(text)\n    \n    # Step 3: Remove URLs, emails, and mentions\n    text = re.sub(r'http\\S+|www\\S+|[\\w\\.-]+@[\\w\\.-]+\\.\\w+|@\\w+', ' ', text)\n    \n    # Step 4: Remove HTML tags and entities\n    text = re.sub(r'<.*?>', ' ', text)\n    text = re.sub(r'&\\w+;', ' ', text)\n    \n    # Step 5: Tokenize into unigrams (individual words)\n    tokens = word_tokenize(text)\n    \n    # Step 6-7: Remove punctuation and stop words\n    tokens = [token for token in tokens \n              if token not in string.punctuation \n              and token not in stop_words\n              and len(token) > 1]  # Remove single characters\n    \n    # Step 8: Lemmatization\n    tokens = [lemmatizer.lemmatize(token, pos='v') for token in tokens]  # Lemmatize verbs\n    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # General lemmatization\n    \n    # Step 9: Simple spell correction (optional, for very misspelled words)\n    # tokens = [simple_spell_check(token, common_words) for token in tokens]\n        \n    return tokens\n\n# Test the preprocessing function\ntest_review = \"I can't believe how amazing this game is! The graphics are absolutely stunning & the gameplay is very engaging. However, there r some bugs that need fixing. Don't worry, it's still the best RPG ever! #BG3 #DnD\"\nprint(\"Original text:\")\nprint(test_review)\nprint(\"\\nCleaned text:\")\nprint(preprocess_text(test_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39505a19",
   "metadata": {},
   "source": [
    "## Step 2: Apply Preprocessing to 'text' Column\n",
    "\n",
    "Now we apply the comprehensive preprocessing pipeline to the entire 'text' column in our dataset. This creates a cleaned version of the text that is ready for feature extraction and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76ff6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text data... This may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample preprocessing results:\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Original text:\n",
      "I cannot recommend this game enough. Larian has made a masterpiece that has surpassed all recent games over the last couple of decades, and will still shine above all others for decades to come. This ...\n",
      "\n",
      "Cleaned text:\n",
      "['recommend', 'game', 'enough', 'larian', 'make', 'masterpiece', 'surpass', 'recent', 'game', 'last', 'couple', 'decade', 'still', 'shine', 'others', 'decade', 'come', 'game', 'equivalent', 'lord', 'ring', 'trilogy', 'every', 'bite', 'praise', 'game', 'company', 'get', 'fully', 'deserve', 'let', 'know', 'game', 'undoubtedly', 'go', 'history', 'one', 'greatest', 'rpg', \"'s\", 'true', 'name', 'congratulation', 'everyone', 'work', 'game', 'truly', 'masterpiece', 'also', 'take', 'money', 'next', 'project']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Original text:\n",
      "A game I can just sit and play for hours, every save is a different adventure....\n",
      "\n",
      "Cleaned text:\n",
      "['game', 'sit', 'play', 'hour', 'every', 'save', 'different', 'adventure']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Original text:\n",
      "Great game hard to figure out the cam and things at first. Great story. Very much a DnD TT type play with great graphics....\n",
      "\n",
      "Cleaned text:\n",
      "['great', 'game', 'hard', 'figure', 'cam', 'thing', 'first', 'great', 'story', 'much', 'dnd', 'tt', 'type', 'play', 'great', 'graphic']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total documents: 33772\n",
      "Empty cleaned texts: 7\n",
      "Non-empty texts: 33765\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe with cleaned text\ndf_cleaned = df.copy()\n\n# Apply preprocessing to the 'text' column\nprint(\"Processing text data... This may take a moment.\")\ndf_cleaned['text_cleaned'] = df_cleaned['text'].apply(preprocess_text)\n\n# Display sample results\nprint(\"\\nSample preprocessing results:\")\nprint(\"=\"*80)\nfor idx in range(min(3, len(df_cleaned))):\n    print(f\"\\nExample {idx + 1}:\")\n    print(f\"Original text:\\n{df_cleaned['text'].iloc[idx][:200]}...\")\n    print(f\"\\nCleaned text:\\n{df_cleaned['text_cleaned'].iloc[idx][:200]}...\")\n    print(\"-\"*80)\n\n# Check for empty cleaned texts\nempty_texts = df_cleaned['text_cleaned'].apply(lambda x: len(x) == 0)\nprint(f\"\\nTotal documents: {len(df_cleaned)}\")\nprint(f\"Empty cleaned texts: {empty_texts.sum()}\")\nprint(f\"Non-empty texts: {(~empty_texts).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001002de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: bg3_reviews_train_cleaned.csv\n",
      "Dataset shape: (33772, 4)\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to a separate CSV file\n",
    "output_path = 'bg3_reviews_train_cleaned.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd5c90",
   "metadata": {},
   "source": [
    "## Step 3: Count Vectorizer - Document-Term Matrix\n",
    "\n",
    "### What is Count Vectorizer?\n",
    "**Count Vectorizer** converts a collection of text documents into a matrix of token counts. Each row represents a document, and each column represents a unique word (term) in the vocabulary. The values in the matrix are the frequencies of each term in each document.\n",
    "\n",
    "### Terminology:\n",
    "- **Corpus**: Collection of all text documents\n",
    "- **Document**: Individual text piece (review)\n",
    "- **Term**: A word or n-gram\n",
    "- **Vocabulary**: Complete list of unique terms in the corpus\n",
    "- **Bag of Words (BoW)**: Representation that ignores word order but keeps frequency\n",
    "\n",
    "### Key Parameters:\n",
    "- `lowercase`: Convert all text to lowercase (default: True)\n",
    "- `ngram_range`: Range for n-grams (1,1) = unigrams, (1,2) = unigrams + bigrams\n",
    "- `stop_words`: Remove common words (already done in preprocessing)\n",
    "- `max_features`: Limit vocabulary size to top N features by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a57134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Results:\n",
      "================================================================================\n",
      "Document-Term Matrix shape: (33772, 1000)\n",
      "Number of documents: 33772\n",
      "Number of unique terms (vocabulary size): 1000\n",
      "\n",
      "Vocabulary sample (first 20 terms):\n",
      "[\"''\" \"'s\" '--' '..' '...' '....' '1.' '10' '10/10' '100' '11/10' '12'\n",
      " '15' '2.' '20' '200' '2023' '3.' '30' '300']\n",
      "\n",
      "Vocabulary sample (random 20 terms):\n",
      "['suppose' 'specific' 'black' 'across' 'move' 'yes' 'background' 'dnd'\n",
      " 'close' 'mix' 'microtransactions' 'prove' 'light' 'support' 'style'\n",
      " 'satisfy' 'case' 'grip' 'part' 'medium']\n"
     ]
    }
   ],
   "source": [
    "# Initialize Count Vectorizer with pre-tokenized input\n",
    "cv = CountVectorizer(\n",
    "    lowercase=False,        # already lowercase in preprocessing\n",
    "    analyzer=lambda x: x,   # passthrough tokens\n",
    "    ngram_range=(1, 1),     # Use unigrams only\n",
    "    max_features=1000,      # Limit to top 1000 features\n",
    "    min_df=2,               # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8              # Ignore terms that appear in more than 80% of documents\n",
    ")\n",
    "\n",
    "# Fit and transform the cleaned text data\n",
    "cv_matrix = cv.fit_transform(df_cleaned['text_cleaned'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "\n",
    "print(\"Count Vectorizer Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Document-Term Matrix shape: {cv_matrix.shape}\")\n",
    "print(f\"Number of documents: {cv_matrix.shape[0]}\")\n",
    "print(f\"Number of unique terms (vocabulary size): {cv_matrix.shape[1]}\")\n",
    "print(f\"\\nVocabulary sample (first 20 terms):\")\n",
    "print(feature_names[:20])\n",
    "print(f\"\\nVocabulary sample (random 20 terms):\")\n",
    "print(np.random.choice(feature_names, 20, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb42dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count Vectorizer Document-Term Matrix (sample):\n",
      "   ''  's  --  ..  ...  ....  1.  10  10/10  100\n",
      "0   0   1   0   0    0     0   0   0      0    0\n",
      "1   0   0   0   0    0     0   0   0      0    0\n",
      "2   0   0   0   0    0     0   0   0      0    0\n",
      "3   0   0   0   0    0     0   0   0      0    0\n",
      "4   0   0   0   0    0     0   0   0      0    0\n",
      "\n",
      "\n",
      "Term Frequency Analysis:\n",
      "================================================================================\n",
      "Top 20 most frequent terms:\n",
      " 1. game                 - Frequency: 63158\n",
      " 2. play                 - Frequency: 22688\n",
      " 3. like                 - Frequency: 11500\n",
      " 4. character            - Frequency: 10991\n",
      " 5. story                - Frequency: 10364\n",
      " 6. make                 - Frequency: 10215\n",
      " 7. time                 - Frequency: 9824\n",
      " 8. one                  - Frequency: 9596\n",
      " 9. get                  - Frequency: 9585\n",
      "10. love                 - Frequency: 7684\n",
      "11. best                 - Frequency: 7399\n",
      "12. 's                   - Frequency: 7157\n",
      "13. good                 - Frequency: 6811\n",
      "14. hour                 - Frequency: 6418\n",
      "15. even                 - Frequency: 6247\n",
      "16. great                - Frequency: 6037\n",
      "17. every                - Frequency: 5999\n",
      "18. gate                 - Frequency: 5976\n",
      "19. feel                 - Frequency: 5791\n",
      "20. ever                 - Frequency: 5692\n",
      "\n",
      "\n",
      "Document Statistics:\n",
      "Average terms per document: 28.17\n",
      "Max terms in a document: 1227\n",
      "Min terms in a document: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to dense array and create DataFrame for better visualization\n",
    "cv_df = pd.DataFrame(\n",
    "    cv_matrix.toarray(),\n",
    "    columns=feature_names\n",
    ")\n",
    "\n",
    "print(\"\\nCount Vectorizer Document-Term Matrix (sample):\")\n",
    "print(cv_df.iloc[:5, :10])  # First 5 documents, first 10 terms\n",
    "\n",
    "# Analysis of term frequencies\n",
    "print(\"\\n\\nTerm Frequency Analysis:\")\n",
    "print(\"=\"*80)\n",
    "term_freq = cv_matrix.sum(axis=0).A1  # Sum frequencies across all documents\n",
    "top_terms_idx = np.argsort(term_freq)[-20:][::-1]  # Top 20 terms\n",
    "print(\"Top 20 most frequent terms:\")\n",
    "for i, idx in enumerate(top_terms_idx, 1):\n",
    "    print(f\"{i:2d}. {feature_names[idx]:20s} - Frequency: {int(term_freq[idx])}\")\n",
    "\n",
    "# Document statistics\n",
    "doc_lengths = cv_matrix.sum(axis=1).A1  # Number of terms per document\n",
    "print(f\"\\n\\nDocument Statistics:\")\n",
    "print(f\"Average terms per document: {doc_lengths.mean():.2f}\")\n",
    "print(f\"Max terms in a document: {doc_lengths.max():.0f}\")\n",
    "print(f\"Min terms in a document: {doc_lengths.min():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d96e7b",
   "metadata": {},
   "source": [
    "## Step 4: TF-IDF Vectorizer - Weighted Document-Term Matrix\n",
    "\n",
    "### What is TF-IDF?\n",
    "**TF-IDF** (Term Frequency-Inverse Document Frequency) assigns weights to terms based on their importance. It balances the frequency of a term in a document with its rarity across all documents.\n",
    "\n",
    "### Formula Breakdown:\n",
    "- **TF (Term Frequency)**: How often a term appears in a document / Total terms in document\n",
    "- **IDF (Inverse Document Frequency)**: log(Total documents / Documents containing term)\n",
    "- **TF-IDF**: TF \u00d7 IDF\n",
    "\n",
    "### Key Insight:\n",
    "- **Rare words** (appear in few documents) \u2192 Higher IDF \u2192 Higher weight (more distinctive)\n",
    "- **Common words** (appear in many documents) \u2192 Lower IDF \u2192 Lower weight (less informative)\n",
    "\n",
    "This addresses limitations of Count Vectorizer where common words may dominate despite being less meaningful for document analysis.\n",
    "\n",
    "### Scikit-learn TF-IDF Implementation:\n",
    "- Uses **natural logarithm (ln)** for IDF calculation\n",
    "- Normalizes resulting TF-IDF vectors using **Euclidean norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b525af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer Results:\n",
      "================================================================================\n",
      "Document-Term Matrix shape: (33772, 1000)\n",
      "Number of documents: 33772\n",
      "Number of unique terms: 1000\n",
      "Sparsity: 97.76%\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer with unigrams\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=False,        # already lowercase in preprocessing\n",
    "    analyzer=lambda x: x,   # passthrough tokens\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=1000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    norm='l2',\n",
    "    sublinear_tf=False\n",
    ")\n",
    "\n",
    "# Fit and transform the cleaned text data\n",
    "tfidf_matrix = tfidf.fit_transform(df_cleaned['text_cleaned'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"TF-IDF Vectorizer Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Document-Term Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of documents: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"Number of unique terms: {tfidf_matrix.shape[1]}\")\n",
    "print(f\"Sparsity: {(1.0 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2420a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Document-Term Matrix (sample):\n",
      "    ''        's   --   ..  ...  ....   1.   10  10/10  100\n",
      "0  0.0  0.101786  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "1  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "2  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "3  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "4  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "\n",
      "\n",
      "TF-IDF Weight Analysis:\n",
      "================================================================================\n",
      "Top 20 terms by TF-IDF weight:\n",
      " 1. game                 - Total TF-IDF: 3540.6294\n",
      " 2. play                 - Total TF-IDF: 1988.3072\n",
      " 3. best                 - Total TF-IDF: 1123.3716\n",
      " 4. like                 - Total TF-IDF: 1077.7923\n",
      " 5. one                  - Total TF-IDF: 1064.7219\n",
      " 6. time                 - Total TF-IDF: 1033.7402\n",
      " 7. story                - Total TF-IDF: 1011.2797\n",
      " 8. make                 - Total TF-IDF: 987.7363\n",
      " 9. love                 - Total TF-IDF: 976.0715\n",
      "10. get                  - Total TF-IDF: 974.2457\n",
      "11. character            - Total TF-IDF: 945.3178\n",
      "12. great                - Total TF-IDF: 898.7144\n",
      "13. ever                 - Total TF-IDF: 895.7205\n",
      "14. good                 - Total TF-IDF: 840.6147\n",
      "15. hour                 - Total TF-IDF: 799.3583\n",
      "16. amaze                - Total TF-IDF: 739.7375\n",
      "17. fun                  - Total TF-IDF: 724.6512\n",
      "18. rpg                  - Total TF-IDF: 719.5175\n",
      "19. 's                   - Total TF-IDF: 704.3590\n",
      "20. much                 - Total TF-IDF: 669.7218\n",
      "\n",
      "\n",
      "Comparison: Count Vectorizer vs TF-IDF\n",
      "================================================================================\n",
      "Count Vectorizer top 20 terms: [\"'s\", 'best', 'character', 'even', 'ever', 'every', 'feel', 'game', 'gate', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'one', 'play', 'story', 'time']\n",
      "\n",
      "TF-IDF top 20 terms: [\"'s\", 'amaze', 'best', 'character', 'ever', 'fun', 'game', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'much', 'one', 'play', 'rpg', 'story', 'time']\n",
      "\n",
      "Terms appearing in both lists: 16 out of 20\n",
      "Common terms: [\"'s\", 'best', 'character', 'ever', 'game', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'one', 'play', 'story', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_feature_names\n",
    ")\n",
    "\n",
    "print(\"\\nTF-IDF Document-Term Matrix (sample):\")\n",
    "print(tfidf_df.iloc[:5, :10])  # First 5 documents, first 10 terms\n",
    "\n",
    "# Analyze TF-IDF weights\n",
    "print(\"\\n\\nTF-IDF Weight Analysis:\")\n",
    "print(\"=\"*80)\n",
    "tfidf_weights = tfidf_matrix.sum(axis=0).A1\n",
    "top_weighted_idx = np.argsort(tfidf_weights)[-20:][::-1]\n",
    "\n",
    "print(\"Top 20 terms by TF-IDF weight:\")\n",
    "for i, idx in enumerate(top_weighted_idx, 1):\n",
    "    print(f\"{i:2d}. {tfidf_feature_names[idx]:20s} - Total TF-IDF: {tfidf_weights[idx]:.4f}\")\n",
    "\n",
    "# Compare top terms in Count vs TF-IDF\n",
    "print(\"\\n\\nComparison: Count Vectorizer vs TF-IDF\")\n",
    "print(\"=\"*80)\n",
    "count_top_20 = set([feature_names[i] for i in np.argsort(term_freq)[-20:][::-1]])\n",
    "tfidf_top_20 = set([tfidf_feature_names[i] for i in np.argsort(tfidf_weights)[-20:][::-1]])\n",
    "common = count_top_20.intersection(tfidf_top_20)\n",
    "\n",
    "print(f\"Count Vectorizer top 20 terms: {sorted(count_top_20)}\")\n",
    "print(f\"\\nTF-IDF top 20 terms: {sorted(tfidf_top_20)}\")\n",
    "print(f\"\\nTerms appearing in both lists: {len(common)} out of 20\")\n",
    "print(f\"Common terms: {sorted(common)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf21b7e",
   "metadata": {},
   "source": [
    "## Step 5: Text Similarity - Cosine Similarity\n",
    "\n",
    "### What is Text Similarity?\n",
    "Text similarity measures how alike two documents are. It's fundamental for:\n",
    "- Information retrieval (finding related documents)\n",
    "- Document clustering (grouping similar reviews)\n",
    "- Topic modeling\n",
    "- Recommendation systems\n",
    "\n",
    "### Cosine Similarity\n",
    "**Cosine Similarity** measures the angle between two document vectors in the vector space.\n",
    "\n",
    "#### Key Properties:\n",
    "- Range: **-1 to 1** (typically 0 to 1 for normalized vectors)\n",
    "- **1.0**: Documents are identical (same direction)\n",
    "- **0.0**: Documents are completely different (perpendicular)\n",
    "- **-1.0**: Documents are opposite (rare for text)\n",
    "\n",
    "#### Why Cosine Similarity for Text?\n",
    "- Focuses on **word overlap**, ignoring document length\n",
    "- Ignores zero values (sparse matrices)\n",
    "- Computationally efficient\n",
    "- Interpretable results (0-1 for text)\n",
    "\n",
    "#### Interpretation:\n",
    "- Similarity > 0.7: Documents are highly similar\n",
    "- Similarity 0.3-0.7: Documents have some similarities\n",
    "- Similarity < 0.3: Documents are quite different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd14b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarity matrix...\n",
      "This may take a moment for larger datasets...\n",
      "\n",
      "Cosine Similarity Matrix shape: (100, 100)\n",
      "Analyzing 100 sample documents\n",
      "\n",
      "\n",
      "Similarity Statistics:\n",
      "================================================================================\n",
      "Mean similarity: 0.0484\n",
      "Median similarity: 0.0306\n",
      "Min similarity: 0.0000\n",
      "Max similarity: 1.0000\n",
      "Std deviation: 0.0566\n",
      "\n",
      "\n",
      "Most Similar Document Pairs (Top 10):\n",
      "================================================================================\n",
      "Document 2605 - Document 18169: 1.0000\n",
      "Document 1031 - Document 11843: 0.4019\n",
      "Document 3938 - Document 19439: 0.3554\n",
      "Document 26304 - Document 14871: 0.3479\n",
      "Document 10250 - Document 11843: 0.3154\n",
      "Document 21355 - Document 11843: 0.3110\n",
      "Document 13897 - Document 11458: 0.3110\n",
      "Document 30355 - Document 2823: 0.3104\n",
      "Document 21355 - Document 14871: 0.3100\n",
      "Document 16430 - Document 11458: 0.3087\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity matrix on full dataset\n",
    "# Using TF-IDF vectors for better semantic representation\n",
    "print(\"Calculating cosine similarity matrix...\")\n",
    "print(\"This may take a moment for larger datasets...\")\n",
    "\n",
    "# For computational efficiency, we'll use a subset of documents\n",
    "# (Full dataset can create very large matrices)\n",
    "sample_size = min(100, len(df_cleaned))  # Use up to 100 documents\n",
    "sample_indices = np.random.choice(len(df_cleaned), sample_size, replace=False)\n",
    "tfidf_sample = tfidf_matrix[sample_indices]\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_sample)\n",
    "\n",
    "print(f\"\\nCosine Similarity Matrix shape: {cosine_sim_matrix.shape}\")\n",
    "print(f\"Analyzing {sample_size} sample documents\")\n",
    "\n",
    "# Analyze similarity statistics\n",
    "print(\"\\n\\nSimilarity Statistics:\")\n",
    "print(\"=\"*80)\n",
    "# Get upper triangle (avoid duplicates and diagonal)\n",
    "upper_triangle = cosine_sim_matrix[np.triu_indices_from(cosine_sim_matrix, k=1)]\n",
    "\n",
    "print(f\"Mean similarity: {upper_triangle.mean():.4f}\")\n",
    "print(f\"Median similarity: {np.median(upper_triangle):.4f}\")\n",
    "print(f\"Min similarity: {upper_triangle.min():.4f}\")\n",
    "print(f\"Max similarity: {upper_triangle.max():.4f}\")\n",
    "print(f\"Std deviation: {upper_triangle.std():.4f}\")\n",
    "\n",
    "# Identify most similar documents\n",
    "print(\"\\n\\nMost Similar Document Pairs (Top 10):\")\n",
    "print(\"=\"*80)\n",
    "# Find indices of highest similarities (excluding diagonal)\n",
    "flat_indices = np.argsort(cosine_sim_matrix.flatten())[::-1]\n",
    "count = 0\n",
    "for flat_idx in flat_indices:\n",
    "    if count >= 10:\n",
    "        break\n",
    "    i, j = np.unravel_index(flat_idx, cosine_sim_matrix.shape)\n",
    "    if i != j and i < j:  # Avoid diagonal and duplicates\n",
    "        print(f\"Document {sample_indices[i]} - Document {sample_indices[j]}: {cosine_sim_matrix[i, j]:.4f}\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a08648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Visualize similarity matrix as heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a smaller sample for visualization (15 documents)\n",
    "viz_size = min(15, sample_size)\n",
    "viz_indices = sample_indices[:viz_size]\n",
    "cosine_sim_viz = cosine_sim_matrix[:viz_size, :viz_size]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cosine_sim_viz, \n",
    "            cmap='YlOrRd', \n",
    "            square=True, \n",
    "            cbar_kws={'label': 'Cosine Similarity'},\n",
    "            xticklabels=[f'Doc {i}' for i in range(viz_size)],\n",
    "            yticklabels=[f'Doc {i}' for i in range(viz_size)])\n",
    "plt.title('Cosine Similarity Matrix Heatmap\\n(Sample of 15 documents)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Heatmap generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221497dd-c2fa-47ba-9815-a4dd07c54fc1",
   "metadata": {},
   "source": [
    "## Findings: Cosine Similarity Heatmap\n",
    "\n",
    "A cosine similarity matrix was visualized using a **sample of 15 documents** to examine pairwise textual similarity between reviews.\n",
    "\n",
    "### Interpretation\n",
    "- Each cell in the heatmap represents the **cosine similarity** between two documents.\n",
    "- Warmer colors (yellow/red) indicate **higher similarity**, while cooler colors indicate **lower similarity**.\n",
    "- The diagonal shows a similarity of **1.0**, as each document is perfectly similar to itself.\n",
    "\n",
    "### Observations\n",
    "- Most off-diagonal values show **moderate to low similarity**, suggesting that the sampled reviews are generally distinct in content.\n",
    "- A few localized regions of higher similarity indicate **clusters of reviews with overlapping themes or language**, potentially reflecting similar feedback topics.\n",
    "- The absence of large high-similarity blocks suggests there is **no excessive duplication** within the sampled reviews.\n",
    "\n",
    "### Implications\n",
    "- The dataset exhibits **meaningful diversity in textual content**, which is suitable for downstream tasks such as classification or clustering.\n",
    "- Observed similarity clusters may correspond to shared discussion points (e.g., gameplay mechanics, narrative elements).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615682cf",
   "metadata": {},
   "source": [
    "## Step 6: Scikit-Learn Pairwise Metrics\n",
    "\n",
    "### What are Pairwise Metrics?\n",
    "Pairwise metrics compute distances or similarities between all pairs of samples in a dataset. Scikit-learn's `pairwise_distances` function provides multiple distance metrics for comprehensive comparison.\n",
    "\n",
    "### Available Distance Metrics:\n",
    "- **Euclidean**: Straight-line distance (good for continuous features)\n",
    "- **Manhattan**: Sum of absolute differences (robust to outliers)\n",
    "- **Cosine**: Angular distance (already covered)\n",
    "- **Hamming**: Number of differing positions (for categorical)\n",
    "- **Jaccard**: (|A\u2229B|) / (|A\u222aB|) - overlap ratio\n",
    "\n",
    "### Use Cases:\n",
    "- Finding nearest neighbors for recommendations\n",
    "- Clustering documents based on similarity\n",
    "- Anomaly detection\n",
    "- Document retrieval systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45306287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Pairwise Metrics...\n",
      "================================================================================\n",
      "Cosine Distance Matrix shape: (50, 50)\n",
      "Euclidean Distance Matrix shape: (50, 50)\n",
      "\n",
      "\n",
      "Cosine Distance Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean cosine distance: 0.9502\n",
      "Median cosine distance: 0.9632\n",
      "Min distance: 0.6417\n",
      "Max distance: 1.0000\n",
      "\n",
      "\n",
      "Euclidean Distance Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean euclidean distance: 1.3780\n",
      "Median euclidean distance: 1.3879\n",
      "Min distance: 1.1329\n",
      "Max distance: 1.4142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_distances, euclidean_distances\n",
    "\n",
    "# Calculate pairwise distances using different metrics\n",
    "print(\"Calculating Pairwise Metrics...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use a smaller sample for computation efficiency\n",
    "pairwise_sample_size = min(50, len(df_cleaned))\n",
    "pairwise_indices = np.random.choice(len(df_cleaned), pairwise_sample_size, replace=False)\n",
    "tfidf_pairwise = tfidf_matrix[pairwise_indices]\n",
    "\n",
    "# Cosine distance (1 - cosine similarity)\n",
    "cosine_dist = cosine_distances(tfidf_pairwise)\n",
    "\n",
    "# Euclidean distance\n",
    "euclidean_dist = euclidean_distances(tfidf_pairwise)\n",
    "\n",
    "print(f\"Cosine Distance Matrix shape: {cosine_dist.shape}\")\n",
    "print(f\"Euclidean Distance Matrix shape: {euclidean_dist.shape}\")\n",
    "\n",
    "# Analyze distances\n",
    "print(\"\\n\\nCosine Distance Statistics:\")\n",
    "print(\"-\"*80)\n",
    "upper_cosine = cosine_dist[np.triu_indices_from(cosine_dist, k=1)]\n",
    "print(f\"Mean cosine distance: {upper_cosine.mean():.4f}\")\n",
    "print(f\"Median cosine distance: {np.median(upper_cosine):.4f}\")\n",
    "print(f\"Min distance: {upper_cosine.min():.4f}\")\n",
    "print(f\"Max distance: {upper_cosine.max():.4f}\")\n",
    "\n",
    "print(\"\\n\\nEuclidean Distance Statistics:\")\n",
    "print(\"-\"*80)\n",
    "upper_euclidean = euclidean_dist[np.triu_indices_from(euclidean_dist, k=1)]\n",
    "print(f\"Mean euclidean distance: {upper_euclidean.mean():.4f}\")\n",
    "print(f\"Median euclidean distance: {np.median(upper_euclidean):.4f}\")\n",
    "print(f\"Min distance: {upper_euclidean.min():.4f}\")\n",
    "print(f\"Max distance: {upper_euclidean.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb859a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finding Nearest Neighbors (k=5):\n",
      "================================================================================\n",
      "\n",
      "Document 25610:\n",
      "Original text: There are small mechanics/things that are frustrating here and there, but these are so easily forgotten and forgiven with the amazing writing and free...\n",
      "Cleaned text: ['small', 'mechanics/things', 'frustrate', 'easily', 'forget', 'forgive', 'amaze', 'write', 'freedom', 'approach', 'give', 'companion', 'many', 'unique', 'truly', 'heartfelt', 'opinion', 'interaction', 'base', 'choice', 'make', 'throughout', 'game', 'start', 'class/background', 'character', 'creation', '...', 'hour', 'upon', 'hour', 'voicelines', 'npc', 'might', 'even', 'meet', 'hear', 'small', 'choices/combat', 'result', 'make', '3rd', 'playthrough', 'still', 'find', 'new', 'npc', 'quest', 'even', 'play', 'evil', 'character', 'yet', 'standard', 'consider', 'one', 'best', 'game', 'ever', 'make', 'especially', 'rpg', 'genre', '10', 'million', 'million', 'million', 'particle', 'universe', 'observe', 'larian', 'take', 'best', 'one', 'put', 'game', 'enjoy']\n",
      "\n",
      "5 Nearest Neighbors (by cosine distance):\n",
      "\n",
      "  1. Document 29443 (Similarity: 0.2716)\n",
      "     Text: This might just be the best game I have ever played... I am in love with how choices changes how the game playes out, fr...\n",
      "\n",
      "  2. Document 3398 (Similarity: 0.2052)\n",
      "     Text: This game is mind blowing. Me and one of my best friends started a multiplayer game 5 months ago. We finally finished it...\n",
      "\n",
      "  3. Document 20726 (Similarity: 0.1821)\n",
      "     Text: The amount of love and care Larian has put into this game can be felt through the entire game. BG3 is a game i've sunk h...\n",
      "\n",
      "  4. Document 8226 (Similarity: 0.1727)\n",
      "     Text: Starting with the positives. I'm a huge D&D nerd, and it was awesome seeing the world and gameplay systems so lovingly r...\n",
      "\n",
      "  5. Document 21731 (Similarity: 0.1590)\n",
      "     Text: Easily one of the greatest CRPGs ever made. I'm not saying it's similar to these games (besides being a CRPG, in many wa...\n"
     ]
    }
   ],
   "source": [
    "# Find nearest neighbors for specific documents\n",
    "print(\"\\n\\nFinding Nearest Neighbors (k=5):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def find_nearest_neighbors(distance_matrix, doc_idx, k=5):\n",
    "    \"\"\"Find k nearest neighbors for a given document\"\"\"\n",
    "    distances = distance_matrix[doc_idx]\n",
    "    nearest_indices = np.argsort(distances)[1:k+1]  # Exclude self (index 0)\n",
    "    nearest_distances = distances[nearest_indices]\n",
    "    return nearest_indices, nearest_distances\n",
    "\n",
    "# Select a random document and find its neighbors\n",
    "test_doc_idx = 0\n",
    "print(f\"\\nDocument {pairwise_indices[test_doc_idx]}:\")\n",
    "print(f\"Original text: {df_cleaned['text'].iloc[pairwise_indices[test_doc_idx]][:150]}...\")\n",
    "print(f\"Cleaned text: {df_cleaned['text_cleaned'].iloc[pairwise_indices[test_doc_idx]]}\")\n",
    "\n",
    "print(f\"\\n5 Nearest Neighbors (by cosine distance):\")\n",
    "neighbors_cosine, distances_cosine = find_nearest_neighbors(cosine_dist, test_doc_idx, k=5)\n",
    "for i, (neighbor_idx, distance) in enumerate(zip(neighbors_cosine, distances_cosine), 1):\n",
    "    actual_idx = pairwise_indices[neighbor_idx]\n",
    "    similarity = 1 - distance  # Convert distance to similarity\n",
    "    print(f\"\\n  {i}. Document {actual_idx} (Similarity: {similarity:.4f})\")\n",
    "    print(f\"     Text: {df_cleaned['text'].iloc[actual_idx][:120]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806eb383-df2a-4108-b8bf-7b86f980f888",
   "metadata": {},
   "source": [
    "### Step 7: Labelling (target creation) assign 'Engineering', 'Design', or 'Narrative' based on keywords. Uses priority logic: Engineering > Design > Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f249b73-0c1a-40c4-9f35-3eb6ad69f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n# 1. ENGINEERING (Technical Failures)\n# ==========================================\neng_keywords = [\n    # Core Terms\n    'crash', 'bug', 'lag', 'freeze', 'error', 'glitch', 'performance', 'fps', 'optimize',\n    'stutter', 'latency', 'disconnect', 'server', 'connection', 'ping', 'broken',\n    'launch', 'startup', 'boot', 'screen', 'monitor', 'gpu', 'cpu', 'hardware',\n    'save', 'corrupt', 'loading', 'install', 'update', 'patch', 'driver', 'softlock',\n    \n    # Specific Tech Jargon (Added)\n    'framerate', 'drop', 'spikes', 'rubberband', 'packet', 'loss', 'netcode',\n    'desktop', 'bsod', 'freezing', 'optimization', 'rendering', 'texture', 'pop-in',\n    \n    # UK Spellings & Common Typos (The \"Safety Net\")\n    'optimise', 'optimisation', 'color', 'colour', # UK/US\n    'unplayable', 'crashs', 'crashing', 'crashed', # Lemma misses some irregulars\n    'laggy', 'lagg', 'glitchy', 'buggy',\n    'fps', 'framerates', 'stuttering', 'disconnects'\n]\n\n# ==========================================\n# 2. DESIGN (Gameplay & Mechanics)\n# ==========================================\ndesign_keywords = [\n    # Core Terms\n    'mechanic', 'gameplay', 'combat', 'level', 'balance', 'ui', 'difficulty', 'grind',\n    'control', 'camera', 'system', 'class', 'skill', 'ability', 'loot', 'reward',\n    'economy', 'pacing', 'progression', 'enemy', 'boss', 'ai', 'inventory', 'map',\n    'mission', 'objective', 'tutorial', 'accessibility', 'clunky', 'repetitive',\n    \n    # Specific Design Jargon (Added)\n    'nerf', 'buff', 'op', 'overpowered', 'underpowered', 'hitbox', 'physics',\n    'hud', 'menu', 'interface', 'navigation', 'paywall', 'microtransaction', 'p2w',\n    'shop', 'store', 'unlock', 'crafting', 'perk', 'talent', 'stat', 'stats',\n    \n    # Typos & Variations\n    'balence', 'lvl', 'lvls', 'quests', 'questing', 'difficult', 'boring',\n    'controls', 'handling', 'movement', 'enemies'\n]\n\n# ==========================================\n# 3. NARRATIVE (Story & World)\n# ==========================================\nnarrative_keywords = [\n    # Core Terms\n    'story', 'plot', 'character', 'dialogue', 'writing', 'quest', 'lore', 'cutscene',\n    'ending', 'arc', 'voice', 'actor', 'script', 'cinematic', 'atmosphere', 'setting',\n    'tone', 'narrator', 'choice', 'decision', 'world', 'relationship', 'romance',\n    'emotional', 'immersive', 'music', 'soundtrack',\n    \n    # Specific Narrative Jargon (Added)\n    'dub', 'sub', 'subtitle', 'pacing', 'climax', 'protagonist', 'antagonist',\n    'villain', 'hero', 'personality', 'depth', 'development', 'background',\n    'visual', 'art', 'style', 'graphic', 'aesthetic', # \"Art\" usually goes with Narrative/Vibe\n    \n    # Typos & Variations\n    'stroy', 'char', 'chars', 'dialog', 'dialouge', 'scene', 'scenes',\n    'acting', 'voiceacting', 'va', 'ost', 'bgm'\n]\n\n# 2. Define the Function\ndef get_department(tokens):\n    # Ensure tokens is a list\n    if not isinstance(tokens, list):\n        return None\n    token_set = set(tokens)\n    \n    # Priority 1: Engineering\n    if token_set & set(eng_keywords):\n        return 'Engineering'\n    \n    # Priority 2: Design\n    elif token_set & set(design_keywords):\n        return 'Design'\n    \n    # Priority 3: Narrative\n    elif token_set & set(narrative_keywords):\n        return 'Narrative'\n    \n    # If no keywords match, return None (we will drop these rows)\n    return None\n\n# 3. Apply it to create the new column in df_cleaned\ndf_cleaned['department'] = df_cleaned['text_cleaned'].apply(get_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdf09aff-5f8c-4798-8985-ef6295b7c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept 19623 labeled reviews out of 33772 (58.1%)\n",
      "label distribution:\n",
      "department\n",
      "Design         8047\n",
      "Narrative      6855\n",
      "Engineering    4721\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[game, sit, play, hour, every, save, different...</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, game, hard, figure, cam, thing, first,...</td>\n",
       "      <td>Narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apparently, play, game, review, many, game, s...</td>\n",
       "      <td>Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[like, extensive, story, line, character, fun,...</td>\n",
       "      <td>Narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[game, well, do, masterpiece, take, course, ma...</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_cleaned   department\n",
       "1  [game, sit, play, hour, every, save, different...  Engineering\n",
       "2  [great, game, hard, figure, cam, thing, first,...    Narrative\n",
       "3  [apparently, play, game, review, many, game, s...       Design\n",
       "4  [like, extensive, story, line, character, fun,...    Narrative\n",
       "5  [game, well, do, masterpiece, take, course, ma...  Engineering"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unlabeled rows\n",
    "before_len = len(df_cleaned)\n",
    "df_final = df_cleaned.dropna(subset=['department']).copy()\n",
    "print(f\"kept {len(df_final)} labeled reviews out of {before_len} ({len(df_final)/before_len:.1%})\")\n",
    "\n",
    "# Show the distribution\n",
    "print(\"label distribution:\")\n",
    "print(df_final['department'].value_counts())\n",
    "df_final[['text_cleaned', 'department']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ed9f2-1b25-450e-ac3e-184793b98992",
   "metadata": {},
   "source": [
    "## Findings: Labeled Review Distribution\n\nAfter removing unlabeled rows, **19,623 out of 33,772 reviews** were retained, representing **58.1%** of the original dataset.\n\n### Label Distribution\nThe labeled reviews are distributed across departments:\n\n- **Design**: 8,047 reviews (~41.0%)\n- **Narrative**: 6,855 reviews (~34.9%)\n- **Engineering**: 4,721 reviews (~24.1%)\n\n### Observations\n- The dataset shows **Design-related feedback** as the largest category, accounting for about two-fifths of all labeled reviews.\n- Narrative and Engineering feedback are comparably sized, each contributing roughly one-quarter to one-third of the data.\n- This class imbalance may influence downstream modeling and should be considered during training (e.g., class weighting or resampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4b7d6",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### Text Preprocessing Pipeline Results\n",
    "The comprehensive preprocessing pipeline successfully:\n",
    "1. \u2713 **Expanded contractions** - \"can't\" \u2192 \"cannot\", \"they're\" \u2192 \"they are\"\n",
    "2. \u2713 **Converted to lowercase** - Standardized text case\n",
    "3. \u2713 **Removed punctuation** - Eliminated non-alphanumeric characters\n",
    "4. \u2713 **Lemmatized tokens** - Reduced words to root forms (\"running\" \u2192 \"run\", \"better\" \u2192 \"good\")\n",
    "5. \u2713 **Removed stop words** - Excluded common words like \"the\", \"is\", \"a\"\n",
    "6. \u2713 **Removed special characters** - Cleaned URLs, HTML tags, emojis\n",
    "7. \u2713 **Handled spelling variations** - Framework for spell correction\n",
    "8. \u2713 **Tokenized into unigrams** - Split text into individual words\n",
    "\n",
    "### Feature Engineering Outcomes\n",
    "\n",
    "#### Count Vectorizer Insights:\n",
    "- Represents raw term frequencies in documents\n",
    "- Simple but effective baseline for text analysis\n",
    "- Vocabulary size captures linguistic diversity\n",
    "- Limitations: Common words may dominate, ignores word importance\n",
    "\n",
    "#### TF-IDF Insights:\n",
    "- Improves upon Count Vectorizer by weighting terms\n",
    "- Rare, distinctive words get higher scores\n",
    "- Better captures document semantics\n",
    "- Normalized vectors allow fair comparison across documents\n",
    "\n",
    "#### Text Similarity Analysis:\n",
    "- Cosine similarity identifies semantically related documents\n",
    "- High similarity (>0.7) indicates very similar reviews\n",
    "- Low similarity (<0.3) indicates dissimilar content\n",
    "- Useful for recommendation systems and document clustering\n",
    "\n",
    "### Applications for BG3 Reviews:\n",
    "1. **Customer Feedback Analysis**: Group similar reviews to identify common themes\n",
    "2. **Recommendation System**: Find and recommend similar games to reviewers\n",
    "3. **Sentiment Clustering**: Analyze reviews with similar opinions together\n",
    "4. **Quality Assurance**: Identify duplicate or redundant feedback\n",
    "5. **Content Moderation**: Detect similar harmful or spam reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6bde8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Final Summary Statistics:\n",
      "================================================================================\n",
      "\n",
      "Original Dataset:\n",
      "  - Total reviews: 33772\n",
      "  - Average text length: 372 characters\n",
      "  - Max text length: 7993 characters\n",
      "  - Min text length: 1 characters\n",
      "\n",
      "Cleaned Dataset:\n",
      "  - Total reviews: 33772\n",
      "  - Average cleaned tokens per review: 36 tokens\n",
      "  - Average terms per review: 28\n",
      "\n",
      "Count Vectorizer:\n",
      "  - Vocabulary size: 1000\n",
      "  - Matrix density: 2.24%\n",
      "\n",
      "TF-IDF Vectorizer:\n",
      "  - Vocabulary size: 1000\n",
      "  - Matrix density: 2.24%\n",
      "\n",
      "Similarity Analysis:\n",
      "  - Analyzed documents: 100\n",
      "  - Average cosine similarity: 0.0484\n",
      "  - Max similarity found: 1.0000\n",
      "\n",
      "\n",
      "Output Files:\n",
      "  - Cleaned dataset: bg3_reviews_train_cleaned.csv\n",
      "  - Dataset columns: ['text', 'date', 'source', 'text_cleaned', 'department']\n",
      "\n",
      "\u2713 Text Feature Engineering notebook completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Final summary statistics and export\nprint(\"\\n\\nFinal Summary Statistics:\")\nprint(\"=\"*80)\nprint(f\"\\nOriginal Dataset:\")\nprint(f\"  - Total reviews: {len(df)}\")\nprint(f\"  - Average text length: {df['text'].str.len().mean():.0f} characters\")\nprint(f\"  - Max text length: {df['text'].str.len().max():.0f} characters\")\nprint(f\"  - Min text length: {df['text'].str.len().min():.0f} characters\")\n\nprint(f\"\\nCleaned Dataset:\")\nprint(f\"  - Total reviews: {len(df_cleaned)}\")\nprint(f\"  - Average cleaned tokens per review: {df_cleaned['text_cleaned'].apply(len).mean():.0f} tokens\")\nprint(f\"  - Average terms per review: {doc_lengths.mean():.0f}\")\n\nprint(f\"\\nCount Vectorizer:\")\nprint(f\"  - Vocabulary size: {cv_matrix.shape[1]}\")\nprint(f\"  - Matrix density: {(cv_matrix.nnz / (cv_matrix.shape[0] * cv_matrix.shape[1]) * 100):.2f}%\")\n\nprint(f\"\\nTF-IDF Vectorizer:\")\nprint(f\"  - Vocabulary size: {tfidf_matrix.shape[1]}\")\nprint(f\"  - Matrix density: {(tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]) * 100):.2f}%\")\n\nprint(f\"\\nSimilarity Analysis:\")\nprint(f\"  - Analyzed documents: {sample_size}\")\nprint(f\"  - Average cosine similarity: {upper_triangle.mean():.4f}\")\nprint(f\"  - Max similarity found: {upper_triangle.max():.4f}\")\n\nprint(f\"\\n\\nOutput Files:\")\nprint(f\"  - Cleaned dataset: bg3_reviews_train_cleaned.csv\")\nprint(f\"  - Dataset columns: {list(df_cleaned.columns)}\")\nprint(\"\\n\u2713 Text Feature Engineering notebook completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}