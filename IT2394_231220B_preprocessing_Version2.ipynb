{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe7568d-1773-405c-8a3a-a0822a7db1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text preprocessing libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import string\n",
    "\n",
    "# Feature extraction libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from itertools import combinations\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49df07d",
   "metadata": {},
   "source": [
    "# Text Feature Engineering - BG3 Reviews Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates comprehensive text preprocessing and feature engineering techniques on the BG3 reviews dataset. We will convert unstructured text into meaningful numerical features suitable for machine learning analysis.\n",
    "\n",
    "### Key Learning Objectives:\n",
    "1. **Terminology**: Understand Corpus, Bag of Words, Document, Term, and Vocabulary\n",
    "2. **Count Vectorizer**: Convert text documents to token count matrices\n",
    "3. **TF-IDF Vectorizer**: Implement term frequency-inverse document frequency weighting\n",
    "4. **Text Similarity**: Apply cosine similarity to compare documents\n",
    "5. **Preprocessing Pipeline**: Implement comprehensive text cleaning and normalization\n",
    "\n",
    "### Components to Cover:\n",
    "- Tokenization by unigrams\n",
    "- Case conversion to lowercase\n",
    "- Remove punctuations\n",
    "- Lemmatization\n",
    "- Remove stop words\n",
    "- Strip special characters and noises\n",
    "- Remove spelling errors\n",
    "- Expand contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2bb47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33772, 3)\n",
      "\n",
      "First few rows:\n",
      "                                                text          date source\n",
      "0  I cannot recommend this game enough. Larian ha...  Apr 21, 2025  steam\n",
      "1  A game I can just sit and play for hours, ever...  Nov 25, 2025  steam\n",
      "2  Great game hard to figure out the cam and thin...  May 02, 2025  steam\n",
      "3  Apparently, I am playing this game of reviewin...  Nov 16, 2025  steam\n",
      "4  Like the extensive story line, characters are ...  Nov 14, 2025  steam\n",
      "\n",
      "Column names:\n",
      "['text', 'date', 'source']\n",
      "\n",
      "Data types:\n",
      "text      object\n",
      "date      object\n",
      "source    object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "text      0\n",
      "date      0\n",
      "source    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('bg3_reviews_train.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898c1f1",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing Pipeline\n",
    "\n",
    "We will implement a comprehensive text preprocessing function that applies all cleaning techniques in the correct order:\n",
    "1. Expand contractions (e.g., \"don't\" → \"do not\")\n",
    "2. Convert to lowercase\n",
    "3. Remove URLs and special patterns\n",
    "4. Tokenize into unigrams\n",
    "5. Remove punctuation\n",
    "6. Remove stop words\n",
    "7. Lemmatize words\n",
    "8. Remove spelling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f14173ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I can't believe it's not working. They've done it!\n",
      "After contraction expansion: i cannot believe it is not working. they have done it!\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for expanding common contractions\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text):\n",
    "    \"\"\"\n",
    "    Expand contractions in the text (e.g., don't -> do not)\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(contractions_dict.keys()) + r')\\b')\n",
    "    return pattern.sub(lambda x: contractions_dict[x.group()], text.lower())\n",
    "\n",
    "# Test contraction expansion\n",
    "test_text = \"I can't believe it's not working. They've done it!\"\n",
    "print(\"Original:\", test_text)\n",
    "print(\"After contraction expansion:\", expand_contractions(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10f44a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "I can't believe how amazing this game is! The graphics are absolutely stunning & the gameplay is very engaging. However, there r some bugs that need fixing. Don't worry, it's still the bes[...]\n",
      "\n",
      "Cleaned text:\n",
      "['believe', 'amaze', 'game', 'graphic', 'absolutely', 'stun', 'gameplay', 'engage', 'however', 'bug', 'need', 'fix', 'worry', 'still', 'best', 'rpg', 'ever', 'bg3', 'dnd']\n"
     ]
    }
   ],
   "source": [
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def simple_spell_check(word, dictionary):\n",
    "    \"\"\"\n",
    "    Simple spell checking using edit distance\n",
    "    Returns the closest word in dictionary if edit distance <= 1\n",
    "    \"\"\"\n",
    "    if word in dictionary:\n",
    "        return word\n",
    "    \n",
    "    # Find words with edit distance of 1\n",
    "    candidates = [w for w in dictionary if edit_distance(word, w) == 1]\n",
    "    \n",
    "    if candidates:\n",
    "        return candidates[0]\n",
    "    return word\n",
    "\n",
    "# Create a dictionary of common English words for spell checking\n",
    "common_words = set(stopwords.words('english'))\n",
    "# Add more vocabulary\n",
    "common_words.update(['game', 'good', 'bad', 'love', 'hate', 'great', 'amazing', \n",
    "                     'beautiful', 'terrible', 'excellent', 'poor', 'wonderful'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Comprehensive text preprocessing pipeline\n",
    "    \n",
    "    Steps:\n",
    "    1. Expand contractions\n",
    "    2. Convert to lowercase (included in expand_contractions)\n",
    "    3. Remove URLs and emails\n",
    "    4. Remove special characters and extra whitespace\n",
    "    5. Tokenize by unigrams\n",
    "    6. Remove punctuation\n",
    "    7. Remove stop words\n",
    "    8. Lemmatization\n",
    "    9. Simple spell correction\n",
    "    \n",
    "    Args:\n",
    "        text (str): Raw text to preprocess\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned and processed text\n",
    "    \"\"\"\n",
    "    \n",
    "    # Handle missing values\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Step 1-2: Expand contractions and convert to lowercase\n",
    "    text = expand_contractions(text)\n",
    "    \n",
    "    # Step 3: Remove URLs, emails, and mentions\n",
    "    text = re.sub(r'http\\S+|www\\S+|[\\w\\.-]+@[\\w\\.-]+\\.\\w+|@\\w+', ' ', text)\n",
    "    \n",
    "    # Step 4: Remove HTML tags and entities\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'&\\w+;', ' ', text)\n",
    "    \n",
    "    # Step 5: Tokenize into unigrams (individual words)\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Step 6-7: Remove punctuation and stop words\n",
    "    tokens = [token for token in tokens \n",
    "              if token not in string.punctuation \n",
    "              and token not in stop_words\n",
    "              and len(token) > 1]  # Remove single characters\n",
    "    \n",
    "    # Step 8: Lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token, pos='v') for token in tokens]  # Lemmatize verbs\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # General lemmatization\n",
    "    \n",
    "    # Step 9: Simple spell correction (optional, for very misspelled words)\n",
    "    # tokens = [simple_spell_check(token, common_words) for token in tokens]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "# Test the preprocessing function\n",
    "test_review = \"I can't believe how amazing this game is! The graphics are absolutely stunning & the gameplay is very engaging. However, there r some bugs that need fixing. Don't worry, it's[...]\n",
    "print(\"Original text:\")\n",
    "print(test_review)\n",
    "print(\"\\nCleaned text:\")\n",
    "print(preprocess_text(test_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39505a19",
   "metadata": {},
   "source": [
    "## Step 2: Apply Preprocessing to 'text' Column\n",
    "\n",
    "Now we apply the comprehensive preprocessing pipeline to the entire 'text' column in our dataset. This creates a cleaned version of the text that is ready for feature extraction and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76ff6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text data... This may take a moment.\n",
      "\n",
      "Sample preprocessing results:\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Original text:\n",
      "I cannot recommend this game enough. Larian has made a masterpiece that has surpassed all recent games over the last couple of decades, and will still shine above all others for decades to come. This ...\n",
      "\n",
      "Cleaned text:\n",
      "['recommend', 'game', 'enough', 'larian', 'make', 'masterpiece', 'surpass', 'recent', 'game', 'last', 'couple', 'decade', 'still', 'shine', 'others', 'decade', 'come', 'game', 'equivalent', 'lord', 'ring', 'trilogy', 'every', 'bite', 'praise', 'game', 'company', 'get', 'fully', 'deserve', 'let', 'know', 'game', 'undoubtedly', 'go', 'history', 'one', 'greatest', 'rpg', \"'s\", 'true', 'name', 'congratulation', 'everyone', 'work', 'game', 'truly', 'masterpiece', 'also', 'take', 'money', 'next', 'project']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Original text:\n",
      "A game I can just sit and play for hours, every save is a different adventure....\n",
      "\n",
      "Cleaned text:\n",
      "['game', 'sit', 'play', 'hour', 'every', 'save', 'different', 'adventure']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Original text:\n",
      "Great game hard to figure out the cam and things at first. Great story. Very much a DnD TT type play with great graphics....\n",
      "\n",
      "Cleaned text:\n",
      "['great', 'game', 'hard', 'figure', 'cam', 'thing', 'first', 'great', 'story', 'much', 'dnd', 'tt', 'type', 'play', 'great', 'graphic']...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total documents: 33772\n",
      "Empty cleaned texts: 0\n",
      "Non-empty texts: 33772\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe with cleaned text\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "print(\"Processing text data... This may take a moment.\")\n",
    "df_cleaned['text_cleaned'] = df_cleaned['text'].apply(preprocess_text)\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSample preprocessing results:\")\n",
    "print(\"=\"*80)\n",
    "for idx in range(min(3, len(df_cleaned))):\n",
    "    print(f\"\\nExample {idx + 1}:\")\n",
    "    print(f\"Original text:\\n{df_cleaned['text'].iloc[idx][:200]}...\")\n",
    "    print(f\"\\nCleaned text:\\n{df_cleaned['text_cleaned'].iloc[idx][:200]}...\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "# Check for empty cleaned texts\n",
    "empty_texts = (df_cleaned['text_cleaned'] == '') | (df_cleaned['text_cleaned'].isnull())\n",
    "print(f\"\\nTotal documents: {len(df_cleaned)}\")\n",
    "print(f\"Empty cleaned texts: {empty_texts.sum()}\")\n",
    "print(f\"Non-empty texts: {(~empty_texts).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001002de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: bg3_reviews_train_cleaned.csv\n",
      "Dataset shape: (33772, 4)\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to a separate CSV file\n",
    "output_path = 'bg3_reviews_train_cleaned.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "print(f\"Cleaned dataset saved to: {output_path}\")\n",
    "print(f\"Dataset shape: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd5c90",
   "metadata": {},
   "source": [
    "## Step 3: Count Vectorizer - Document-Term Matrix\n",
    "\n",
    "### What is Count Vectorizer?\n",
    "**Count Vectorizer** converts a collection of text documents into a matrix of token counts. Each row represents a document, and each column represents a unique word (term) in the vocabulary. The values in the matrix are the frequencies of each term in each document.\n",
    "\n",
    "### Terminology:\n",
    "- **Corpus**: Collection of all text documents\n",
    "- **Document**: Individual text piece (review)\n",
    "- **Term**: A word or n-gram\n",
    "- **Vocabulary**: Complete list of unique terms in the corpus\n",
    "- **Bag of Words (BoW)**: Representation that ignores word order but keeps frequency\n",
    "\n",
    "### Key Parameters:\n",
    "- `lowercase`: Convert all text to lowercase (default: True)\n",
    "- `ngram_range`: Range for n-grams (1,1) = unigrams, (1,2) = unigrams + bigrams\n",
    "- `stop_words`: Remove common words (already done in preprocessing)\n",
    "- `max_features`: Limit vocabulary size to top N features by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a57134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Results:\n",
      "================================================================================\n",
      "Document-Term Matrix shape: (33772, 1000)\n",
      "Number of documents: 33772\n",
      "Number of unique terms (vocabulary size): 1000\n",
      "\n",
      "Vocabulary sample (first 20 terms):\n",
      "[\"''\" \"'s\" '--' '..' '...' '....' '1.' '10' '10/10' '100' '11/10' '12'\n",
      " '15' '2.' '20' '200' '2023' '3.' '30' '300']\n",
      "\n",
      "Vocabulary sample (random 20 terms):\n",
      "['terrible' 'mention' 'ruin' 'masterpiece' 'moment' 'another' 'role'\n",
      " 'situation' 'surprise' 'forward' 'value' 'several' 'o' 'eat' 'constantly'\n",
      " 'satisfy' 'course' 'box' 'party' 'scene']\n"
     ]
    }
   ],
   "source": [
    "# Initialize Count Vectorizer with pre-tokenized input\n",
    "cv = CountVectorizer(\n",
    "    lowercase=False,        # already lowercase in preprocessing\n",
    "    analyzer=lambda x: x,   # passthrough tokens\n",
    "    ngram_range=(1, 1),     # Use unigrams only\n",
    "    max_features=1000,      # Limit to top 1000 features\n",
    "    min_df=2,               # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8              # Ignore terms that appear in more than 80% of documents\n",
    ")\n",
    "\n",
    "# Fit and transform the cleaned text data\n",
    "cv_matrix = cv.fit_transform(df_cleaned['text_cleaned'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "\n",
    "print(\"Count Vectorizer Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Document-Term Matrix shape: {cv_matrix.shape}\")\n",
    "print(f\"Number of documents: {cv_matrix.shape[0]}\")\n",
    "print(f\"Number of unique terms (vocabulary size): {cv_matrix.shape[1]}\")\n",
    "print(f\"\\nVocabulary sample (first 20 terms):\")\n",
    "print(feature_names[:20])\n",
    "print(f\"\\nVocabulary sample (random 20 terms):\")\n",
    "print(np.random.choice(feature_names, 20, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb42dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count Vectorizer Document-Term Matrix (sample):\n",
      "   ''  's  --  ..  ...  ....  1.  10  10/10  100\n",
      "0   0   1   0   0    0     0   0   0      0    0\n",
      "1   0   0   0   0    0     0   0   0      0    0\n",
      "2   0   0   0   0    0     0   0   0      0    0\n",
      "3   0   0   0   0    0     0   0   0      0    0\n",
      "4   0   0   0   0    0     0   0   0      0    0\n",
      "\n",
      "\n",
      "Term Frequency Analysis:\n",
      "================================================================================\n",
      "Top 20 most frequent terms:\n",
      " 1. game                 - Frequency: 63158\n",
      " 2. play                 - Frequency: 22688\n",
      " 3. like                 - Frequency: 11500\n",
      " 4. character            - Frequency: 10991\n",
      " 5. story                - Frequency: 10364\n",
      " 6. make                 - Frequency: 10215\n",
      " 7. time                 - Frequency: 9824\n",
      " 8. one                  - Frequency: 9596\n",
      " 9. get                  - Frequency: 9585\n",
      "10. love                 - Frequency: 7684\n",
      "11. best                 - Frequency: 7399\n",
      "12. 's                   - Frequency: 7157\n",
      "13. good                 - Frequency: 6811\n",
      "14. hour                 - Frequency: 6418\n",
      "15. even                 - Frequency: 6247\n",
      "16. great                - Frequency: 6037\n",
      "17. every                - Frequency: 5999\n",
      "18. gate                 - Frequency: 5976\n",
      "19. feel                 - Frequency: 5791\n",
      "20. ever                 - Frequency: 5692\n",
      "\n",
      "\n",
      "Document Statistics:\n",
      "Average terms per document: 28.17\n",
      "Max terms in a document: 1227\n",
      "Min terms in a document: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to dense array and create DataFrame for better visualization\n",
    "cv_df = pd.DataFrame(\n",
    "    cv_matrix.toarray(),\n",
    "    columns=feature_names\n",
    ")\n",
    "print(\"\\nCount Vectorizer Document-Term Matrix (sample):\")\n",
    "print(cv_df.iloc[:5, :10])  # First 5 documents, first 10 terms\n",
    "\n",
    "# Analysis of term frequencies\n",
    "print(\"\\n\\nTerm Frequency Analysis:\")\n",
    "print(\"=\"*80)\n",
    "term_freq = cv_matrix.sum(axis=0).A1  # Sum frequencies across all documents\n",
    "top_terms_idx = np.argsort(term_freq)[-20:][::-1]  # Top 20 terms\n",
    "print(\"Top 20 most frequent terms:\")\n",
    "for i, idx in enumerate(top_terms_idx, 1):\n",
    "    print(f\"{i:2d}. {feature_names[idx]:20s} - Frequency: {int(term_freq[idx])}\")\n",
    "\n",
    "# Document statistics\n",
    "doc_lengths = cv_matrix.sum(axis=1).A1  # Number of terms per document\n",
    "print(f\"\\n\\nDocument Statistics:\")\n",
    "print(f\"Average terms per document: {doc_lengths.mean():.2f}\")\n",
    "print(f\"Max terms in a document: {doc_lengths.max():.0f}\")\n",
    "print(f\"Min terms in a document: {doc_lengths.min():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d96e7b",
   "metadata": {},
   "source": [
    "## Step 4: TF-IDF Vectorizer - Weighted Document-Term Matrix\n",
    "\n",
    "### What is TF-IDF?\n",
    "**TF-IDF** (Term Frequency-Inverse Document Frequency) assigns weights to terms based on their importance. It balances the frequency of a term in a document with its rarity across all documents.\n",
    "\n",
    "### Formula Breakdown:\n",
    "- **TF (Term Frequency)**: How often a term appears in a document / Total terms in document\n",
    "- **IDF (Inverse Document Frequency)**: log(Total documents / Documents containing term)\n",
    "- **TF-IDF**: TF × IDF\n",
    "\n",
    "### Key Insight:\n",
    "- **Rare words** (appear in few documents) → Higher IDF → Higher weight (more distinctive)\n",
    "- **Common words** (appear in many documents) → Lower IDF → Lower weight (less informative)\n",
    "\n",
    "This addresses limitations of Count Vectorizer where common words may dominate despite being less meaningful for document analysis.\n",
    "\n",
    "### Scikit-learn TF-IDF Implementation:\n",
    "- Uses **natural logarithm (ln)** for IDF calculation\n",
    "- Normalizes resulting TF-IDF vectors using **Euclidean norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b525af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorizer Results:\n",
      "================================================================================\n",
      "Document-Term Matrix shape: (33772, 1000)\n",
      "Number of documents: 33772\n",
      "Number of unique terms: 1000\n",
      "Sparsity: 97.76%\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF Vectorizer with unigrams\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=False,        # already lowercase in preprocessing\n",
    "    analyzer=lambda x: x,   # passthrough tokens\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=1000,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    norm='l2',\n",
    "    sublinear_tf=False\n",
    ")\n",
    "\n",
    "# Fit and transform the cleaned text data\n",
    "tfidf_matrix = tfidf.fit_transform(df_cleaned['text_cleaned'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "tfidf_feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "print(\"TF-IDF Vectorizer Results:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Document-Term Matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of documents: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"Number of unique terms: {tfidf_matrix.shape[1]}\")\n",
    "print(f\"Sparsity: {(1.0 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2420a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Document-Term Matrix (sample):\n",
      "    ''        's   --   ..  ...  ....   1.   10  10/10  100\n",
      "0  0.0  0.101786  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "1  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "2  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "3  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "4  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0    0.0  0.0\n",
      "\n",
      "\n",
      "TF-IDF Weight Analysis:\n",
      "================================================================================\n",
      "Top 20 terms by TF-IDF weight:\n",
      " 1. game                 - Total TF-IDF: 3540.6294\n",
      " 2. play                 - Total TF-IDF: 1988.3072\n",
      " 3. best                 - Total TF-IDF: 1123.3716\n",
      " 4. like                 - Total TF-IDF: 1077.7923\n",
      " 5. one                  - Total TF-IDF: 1064.7219\n",
      " 6. time                 - Total TF-IDF: 1033.7402\n",
      " 7. story                - Total TF-IDF: 1011.2797\n",
      " 8. make                 - Total TF-IDF: 987.7363\n",
      " 9. love                 - Total TF-IDF: 976.0715\n",
      "10. get                  - Total TF-IDF: 974.2457\n",
      "11. character            - Total TF-IDF: 945.3178\n",
      "12. great                - Total TF-IDF: 898.7144\n",
      "13. ever                 - Total TF-IDF: 895.7205\n",
      "14. good                 - Total TF-IDF: 840.6147\n",
      "15. hour                 - Total TF-IDF: 799.3583\n",
      "16. amaze                - Total TF-IDF: 739.7375\n",
      "17. fun                  - Total TF-IDF: 724.6512\n",
      "18. rpg                  - Total TF-IDF: 719.5175\n",
      "19. 's                   - Total TF-IDF: 704.3590\n",
      "20. much                 - Total TF-IDF: 669.7218\n",
      "\n",
      "\n",
      "Comparison: Count Vectorizer vs TF-IDF\n",
      "================================================================================\n",
      "Count Vectorizer top 20 terms: [\"'s\", 'best', 'character', 'even', 'ever', 'every', 'feel', 'game', 'gate', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'one', 'play', 'story', 'time']\n",
      "\n",
      "TF-IDF top 20 terms: [\"'s\", 'amaze', 'best', 'character', 'ever', 'fun', 'game', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'much', 'one', 'play', 'rpg', 'story', 'time']\n",
      "\n",
      "Terms appearing in both lists: 16 out of 20\n",
      "Common terms: [\"'s\", 'best', 'character', 'ever', 'game', 'get', 'good', 'great', 'hour', 'like', 'love', 'make', 'one', 'play', 'story', 'time']\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrix to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_feature_names\n",
    ")\n",
    "print(\"\\nTF-IDF Document-Term Matrix (sample):\")\n",
    "print(tfidf_df.iloc[:5, :10])  # First 5 documents, first 10 terms\n",
    "\n",
    "# Analyze TF-IDF weights\n",
    "print(\"\\n\\nTF-IDF Weight Analysis:\")\n",
    "print(\"=\"*80)\n",
    "tfidf_weights = tfidf_matrix.sum(axis=0).A1\n",
    "top_weighted_idx = np.argsort(tfidf_weights)[-20:][::-1]\n",
    "\n",
    "print(\"Top 20 terms by TF-IDF weight:\")\n",
    "for i, idx in enumerate(top_weighted_idx, 1):\n",
    "    print(f\"{i:2d}. {tfidf_feature_names[idx]:20s} - Total TF-IDF: {tfidf_weights[idx]:.4f}\")\n",
    "\n",
    "# Compare top terms in Count vs TF-IDF\n",
    "print(\"\\n\\nComparison: Count Vectorizer vs TF-IDF\")\n",
    "print(\"=\"*80)\n",
    "count_top_20 = set([feature_names[i] for i in np.argsort(term_freq)[-20:][::-1]])\n",
    "tfidf_top_20 = set([tfidf_feature_names[i] for i in np.argsort(tfidf_weights)[-20:][::-1]])\n",
    "common = count_top_20.intersection(tfidf_top_20)\n",
    "\n",
    "print(f\"Count Vectorizer top 20 terms: {sorted(count_top_20)}\")\n",
    "print(f\"\\nTF-IDF top 20 terms: {sorted(tfidf_top_20)}\")\n",
    "print(f\"\\nTerms appearing in both lists: {len(common)} out of 20\")\n",
    "print(f\"Common terms: {sorted(common)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf21b7e",
   "metadata": {},
   "source": [
    "## Step 5: Text Similarity - Cosine Similarity\n",
    "\n",
    "### What is Text Similarity?\n",
    "Text similarity measures how alike two documents are. It's fundamental for:\n",
    "- Information retrieval (finding related documents)\n",
    "- Document clustering (grouping similar reviews)\n",
    "- Topic modeling\n",
    "- Recommendation systems\n",
    "\n",
    "### Cosine Similarity\n",
    "**Cosine Similarity** measures the angle between two document vectors in the vector space.\n",
    "\n",
    "#### Key Properties:\n",
    "- Range: **-1 to 1** (typically 0 to 1 for normalized vectors)\n",
    "- **1.0**: Documents are identical (same direction)\n",
    "- **0.0**: Documents are completely different (perpendicular)\n",
    "- **-1.0**: Documents are opposite (rare for text)\n",
    "\n",
    "#### Why Cosine Similarity for Text?\n",
    "- Focuses on **word overlap**, ignoring document length\n",
    "- Ignores zero values (sparse matrices)\n",
    "- Computationally efficient\n",
    "- Interpretable results (0-1 for text)\n",
    "\n",
    "#### Interpretation:\n",
    "- Similarity > 0.7: Documents are highly similar\n",
    "- Similarity 0.3-0.7: Documents have some similarities\n",
    "- Similarity < 0.3: Documents are quite different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd14b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarity matrix...\n",
      "This may take a moment for larger datasets...\n",
      "\n",
      "Cosine Similarity Matrix shape: (100, 100)\n",
      "Analyzing 100 sample documents\n",
      "\n",
      "\n",
      "Similarity Statistics:\n",
      "================================================================================\n",
      "Mean similarity: 0.0491\n",
      "Median similarity: 0.0310\n",
      "Min similarity: 0.0000\n",
      "Max similarity: 0.4686\n",
      "Std deviation: 0.0559\n",
      "\n",
      "\n",
      "Most Similar Document Pairs (Top 10):\n",
      "================================================================================\n",
      "Document 17423 - Document 5146: 0.4686\n",
      "Document 33549 - Document 6787: 0.3562\n",
      "Document 11983 - Document 22765: 0.3505\n",
      "Document 10184 - Document 33549: 0.3344\n",
      "Document 26197 - Document 13514: 0.3311\n",
      "Document 11983 - Document 6110: 0.3261\n",
      "Document 6508 - Document 33549: 0.3248\n",
      "Document 649 - Document 5146: 0.3136\n",
      "Document 32228 - Document 27945: 0.3093\n",
      "Document 19648 - Document 10556: 0.3048\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity matrix on full dataset\n",
    "# Using TF-IDF vectors for better semantic representation\n",
    "print(\"Calculating cosine similarity matrix...\")\n",
    "print(\"This may take a moment for larger datasets...\")\n",
    "\n",
    "# For computational efficiency, we'll use a subset of documents\n",
    "# (Full dataset can create very large matrices)\n",
    "sample_size = min(100, len(df_cleaned))  # Use up to 100 documents\n",
    "sample_indices = np.random.choice(len(df_cleaned), sample_size, replace=False)\n",
    "tfidf_sample = tfidf_matrix[sample_indices]\n",
    "\n",
    "# Calculate cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_sample)\n",
    "\n",
    "print(f\"\\nCosine Similarity Matrix shape: {cosine_sim_matrix.shape}\")\n",
    "print(f\"Analyzing {sample_size} sample documents\")\n",
    "\n",
    "# Analyze similarity statistics\n",
    "print(\"\\n\\nSimilarity Statistics:\")\n",
    "print(\"=\"*80)\n",
    "# Get upper triangle (avoid duplicates and diagonal)\n",
    "upper_triangle = cosine_sim_matrix[np.triu_indices_from(cosine_sim_matrix, k=1)]\n",
    "\n",
    "print(f\"Mean similarity: {upper_triangle.mean():.4f}\")\n",
    "print(f\"Median similarity: {np.median(upper_triangle):.4f}\")\n",
    "print(f\"Min similarity: {upper_triangle.min():.4f}\")\n",
    "print(f\"Max similarity: {upper_triangle.max():.4f}\")\n",
    "print(f\"Std deviation: {upper_triangle.std():.4f}\")\n",
    "\n",
    "# Identify most similar documents\n",
    "print(\"\\n\\nMost Similar Document Pairs (Top 10):\")\n",
    "print(\"=\"*80)\n",
    "# Find indices of highest similarities (excluding diagonal)\n",
    "flat_indices = np.argsort(cosine_sim_matrix.flatten())[::-1]\n",
    "count = 0\n",
    "for flat_idx in flat_indices:\n",
    "    if count >= 10:\n",
    "        break\n",
    "    i, j = np.unravel_index(flat_idx, cosine_sim_matrix.shape)\n",
    "    if i != j and i < j:  # Avoid diagonal and duplicates\n",
    "        print(f\"Document {sample_indices[i]} - Document {sample_indices[j]}: {cosine_sim_matrix[i, j]:.4f}\")\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a08648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAMWCAYAAABbcN+TAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAofhJREF[...very long base64...omitted here for brevity...]",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Visualize similarity matrix as heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a smaller sample for visualization (15 documents)\n",
    "viz_size = min(15, sample_size)\n",
    "viz_indices = sample_indices[:viz_size]\n",
    "cosine_sim_viz = cosine_sim_matrix[:viz_size, :viz_size]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cosine_sim_viz, \n",
    "            cmap='YlOrRd', \n",
    "            square=True, \n",
    "            cbar_kws={'label': 'Cosine Similarity'},\n",
    "            xticklabels=[f'Doc {i}' for i in range(viz_size)],\n",
    "            yticklabels=[f'Doc {i}' for i in range(viz_size)])\n",
    "plt.title('Cosine Similarity Matrix Heatmap\\n(Sample of 15 documents)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Heatmap generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221497dd-c2fa-47ba-9815-a4dd07c54fc1",
   "metadata": {},
   "source": [
    "## Findings: Cosine Similarity Heatmap\n",
    "\n",
    "A cosine similarity matrix was visualized using a **sample of 15 documents** to examine pairwise textual similarity between reviews.\n",
    "\n",
    "### Interpretation\n",
    "- Each cell in the heatmap represents the **cosine similarity** between two documents.\n",
    "- Warmer colors (yellow/red) indicate **higher similarity**, while cooler colors indicate **lower similarity**.\n",
    "- The diagonal shows a similarity of **1.0**, as each document is perfectly similar to itself.\n",
    "\n",
    "### Observations\n",
    "- Most off-diagonal values show **moderate to low similarity**, suggesting that the sampled reviews are generally distinct in content.\n",
    "- A few localized regions of higher similarity indicate **clusters of reviews with overlapping themes or language**, potentially reflecting similar feedback topics.\n",
    "- The absence of large high-similarity blocks suggests there is **no excessive duplication** within the sampled reviews.\n",
    "\n",
    "### Implications\n",
    "- The dataset exhibits **meaningful diversity in textual content**, which is suitable for downstream tasks such as classification or clustering.\n",
    "- Observed similarity clusters may correspond to shared discussion points (e.g., gameplay mechanics, narrative elements).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615682cf",
   "metadata": {},
   "source": [
    "## Step 6: Scikit-Learn Pairwise Metrics\n",
    "\n",
    "### What are Pairwise Metrics?\n",
    "Pairwise metrics compute distances or similarities between all pairs of samples in a dataset. Scikit-learn's `pairwise_distances` function provides multiple distance metrics for comprehensive comparison.\n",
    "\n",
    "### Available Distance Metrics:\n",
    "- **Euclidean**: Straight-line distance (good for continuous features)\n",
    "- **Manhattan**: Sum of absolute differences (robust to outliers)\n",
    "- **Cosine**: Angular distance (already covered)\n",
    "- **Hamming**: Number of differing positions (for categorical)\n",
    "- **Jaccard**: (|A∩B|) / (|A∪B|) - overlap ratio\n",
    "\n",
    "### Use Cases:\n",
    "- Finding nearest neighbors for recommendations\n",
    "- Clustering documents based on similarity\n",
    "- Anomaly detection\n",
    "- Document retrieval systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45306287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Pairwise Metrics...\n",
      "================================================================================\n",
      "Cosine Distance Matrix shape: (50, 50)\n",
      "Euclidean Distance Matrix shape: (50, 50)\n",
      "\n",
      "\n",
      "Cosine Distance Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean cosine distance: 0.9484\n",
      "Median cosine distance: 0.9655\n",
      "Min distance: 0.6251\n",
      "Max distance: 1.0000\n",
      "\n",
      "\n",
      "Euclidean Distance Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Mean euclidean distance: 1.3766\n",
      "Median euclidean distance: 1.3896\n",
      "Min distance: 1.1181\n",
      "Max distance: 1.4142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances, cosine_distances, euclidean_distances\n",
    "\n",
    "# Calculate pairwise distances using different metrics\n",
    "print(\"Calculating Pairwise Metrics...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use a smaller sample for computation efficiency\n",
    "pairwise_sample_size = min(50, len(df_cleaned))\n",
    "pairwise_indices = np.random.choice(len(df_cleaned), pairwise_sample_size, replace=False)\n",
    "tfidf_pairwise = tfidf_matrix[pairwise_indices]\n",
    "\n",
    "# Cosine distance (1 - cosine similarity)\n",
    "cosine_dist = cosine_distances(tfidf_pairwise)\n",
    "\n",
    "# Euclidean distance\n",
    "euclidean_dist = euclidean_distances(tfidf_pairwise)\n",
    "\n",
    "print(f\"Cosine Distance Matrix shape: {cosine_dist.shape}\")\n",
    "print(f\"Euclidean Distance Matrix shape: {euclidean_dist.shape}\")\n",
    "\n",
    "# Analyze distances\n",
    "print(\"\\n\\nCosine Distance Statistics:\")\n",
    "print(\"-\"*80)\n",
    "upper_cosine = cosine_dist[np.triu_indices_from(cosine_dist, k=1)]\n",
    "print(f\"Mean cosine distance: {upper_cosine.mean():.4f}\")\n",
    "print(f\"Median cosine distance: {np.median(upper_cosine):.4f}\")\n",
    "print(f\"Min distance: {upper_cosine.min():.4f}\")\n",
    "print(f\"Max distance: {upper_cosine.max():.4f}\")\n",
    "\n",
    "print(\"\\n\\nEuclidean Distance Statistics:\")\n",
    "print(\"-\"*80)\n",
    "upper_euclidean = euclidean_dist[np.triu_indices_from(euclidean_dist, k=1)]\n",
    "print(f\"Mean euclidean distance: {upper_euclidean.mean():.4f}\")\n",
    "print(f\"Median euclidean distance: {np.median(upper_euclidean):.4f}\")\n",
    "print(f\"Min distance: {upper_euclidean.min():.4f}\")\n",
    "print(f\"Max distance: {upper_euclidean.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb859a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Finding Nearest Neighbors (k=5):\n",
      "================================================================================\n",
      "\n",
      "Document 21370:\n",
      "Original text: 312 hours, multiple saves and playthroughs both solo and with friends. Still yet to complete the story, still discovering new things each time. Incred...\n",
      "Cleaned text: ['312', 'hour', 'multiple', 'save', 'playthroughs', 'solo', 'friend', 'still', 'yet', 'complete', 'story', 'still', 'discover', 'new', 'thing', 'time', 'incredible']\n",
      "\n",
      "5 Nearest Neighbors (by cosine distance):\n",
      "\n",
      "  1. Document 13380 (Similarity: 0.2233)\n",
      "     Text: Always feel like the choices I make really affect the story of the character I'm playing, and that allows it to feel fre...\n",
      "\n",
      "  2. Document 14465 (Similarity: 0.1349)\n",
      "     Text: Put in 100+ hours into Baldur’s Gate 3 and honestly never felt bored even once. Every choice actually matters, every fig...\n",
      "\n",
      "  3. Document 14356 (Similarity: 0.1063)\n",
      "     Text: This is one of the best games I have played in a while. I can keep coming to it to play different characters and story o...\n",
      "\n",
      "  4. Document 15859 (Similarity: 0.1045)\n",
      "     Text: I have played Baldur's Gate 3 for 170 hour and this game is literally fascinating and I think it is one of the closest t...\n",
      "\n",
      "  5. Document 17643 (Similarity: 0.1030)\n",
      "     Text: There's a lot that I really like about this game; The characters (even though I feel like the way the game works somewha...\n"
     ]
    }
   ],
   "source": [
    "# Find nearest neighbors for specific documents\n",
    "print(\"\\n\\nFinding Nearest Neighbors (k=5):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def find_nearest_neighbors(distance_matrix, doc_idx, k=5):\n",
    "    \"\"\"Find k nearest neighbors for a given document\"\"\"\n",
    "    distances = distance_matrix[doc_idx]\n",
    "    nearest_indices = np.argsort(distances)[1:k+1]  # Exclude self (index 0)\n",
    "    nearest_distances = distances[nearest_indices]\n",
    "    return nearest_indices, nearest_distances\n",
    "\n",
    "# Select a random document and find its neighbors\n",
    "test_doc_idx = 0\n",
    "print(f\"\\nDocument {pairwise_indices[test_doc_idx]}:\")\n",
    "print(f\"Original text: {df_cleaned['text'].iloc[pairwise_indices[test_doc_idx]][:150]}...\")\n",
    "print(f\"Cleaned text: {df_cleaned['text_cleaned'].iloc[pairwise_indices[test_doc_idx]]}\\")\n",
    "\n",
    "print(f\"\\n5 Nearest Neighbors (by cosine distance):\")\n",
    "neighbors_cosine, distances_cosine = find_nearest_neighbors(cosine_dist, test_doc_idx, k=5)\n",
    "for i, (neighbor_idx, distance) in enumerate(zip(neighbors_cosine, distances_cosine), 1):\n",
    "    actual_idx = pairwise_indices[neighbor_idx]\n",
    "    similarity = 1 - distance  # Convert distance to similarity\n",
    "    print(f\"\\n  {i}. Document {actual_idx} (Similarity: {similarity:.4f})\")\n",
    "    print(f\"     Text: {df_cleaned['text'].iloc[actual_idx][:120]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806eb383-df2a-4108-b8bf-7b86f980f888",
   "metadata": {},
   "source": [
    "### Step 7: Labelling (target creation) assign 'Engineering', 'Design', or 'Narrative' based on keywords. Uses priority logic: Engineering > Design > Narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f249b73-0c1a-40c4-9f35-3eb6ad69f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. ENGINEERING (Technical Failures)\n",
    "# ==========================================\n",
    "eng_keywords = [\n",
    "    # Core Terms\n",
    "    'crash', 'bug', 'lag', 'freeze', 'error', 'glitch', 'performance', 'fps', 'optimize',\n",
    "    'stutter', 'latency', 'disconnect', 'server', 'connection', 'ping', 'broken',\n",
    "    'launch', 'startup', 'boot', 'screen', 'monitor', 'gpu', 'cpu', 'hardware',\n",
    "    'save', 'corrupt', 'loading', 'install', 'update', 'patch', 'driver', 'softlock',\n",
    "    \n",
    "    # Specific Tech Jargon (Added)\n",
    "    'framerate', 'drop', 'spikes', 'rubberband', 'packet', 'loss', 'netcode',\n",
    "    'desktop', 'bsod', 'freezing', 'optimization', 'rendering', 'texture', 'pop-in',\n",
    "    \n",
    "    # UK Spellings & Common Typos (The \"Safety Net\")\n",
    "    'optimise', 'optimisation', 'color', 'colour', # UK/US\n",
    "    'unplayable', 'crashs', 'crashing', 'crashed', # Lemma misses some irregulars\n",
    "    'laggy', 'lagg', 'glitchy', 'buggy',\n",
    "    'fps', 'framerates', 'stuttering', 'disconnects'\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 2. DESIGN (Gameplay & Mechanics)\n",
    "# ==========================================\n",
    "design_keywords = [\n",
    "    # Core Terms\n",
    "    'mechanic', 'gameplay', 'combat', 'level', 'balance', 'ui', 'difficulty', 'grind',\n",
    "    'control', 'camera', 'system', 'class', 'skill', 'ability', 'loot', 'reward',\n",
    "    'economy', 'pacing', 'progression', 'enemy', 'boss', 'ai', 'inventory', 'map',\n",
    "    'mission', 'objective', 'tutorial', 'accessibility', 'clunky', 'repetitive',\n",
    "    \n",
    "    # Specific Design Jargon (Added)\n",
    "    'nerf', 'buff', 'op', 'overpowered', 'underpowered', 'hitbox', 'physics',\n",
    "    'hud', 'menu', 'interface', 'navigation', 'paywall', 'microtransaction', 'p2w',\n",
    "    'shop', 'store', 'unlock', 'crafting', 'perk', 'talent', 'stat', 'stats',\n",
    "    \n",
    "    # Typos & Variations\n",
    "    'balence', 'lvl', 'lvls', 'quests', 'questing', 'difficult', 'boring',\n",
    "    'controls', 'handling', 'movement', 'enemies'\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 3. NARRATIVE (Story & World)\n",
    "# ==========================================\n",
    "narrative_keywords = [\n",
    "    # Core Terms\n",
    "    'story', 'plot', 'character', 'dialogue', 'writing', 'quest', 'lore', 'cutscene',\n",
    "    'ending', 'arc', 'voice', 'actor', 'script', 'cinematic', 'atmosphere', 'setting',\n",
    "    'tone', 'narrator', 'choice', 'decision', 'world', 'relationship', 'romance',\n",
    "    'emotional', 'immersive', 'music', 'soundtrack',\n",
    "    \n",
    "    # Specific Narrative Jargon (Added)\n",
    "    'dub', 'sub', 'subtitle', 'pacing', 'climax', 'protagonist', 'antagonist',\n",
    "    'villain', 'hero', 'personality', 'depth', 'development', 'background',\n",
    "    'visual', 'art', 'style', 'graphic', 'aesthetic', # \"Art\" usually goes with Narrative/Vibe\n",
    "    \n",
    "    # Typos & Variations\n",
    "    'stroy', 'char', 'chars', 'dialog', 'dialouge', 'scene', 'scenes',\n",
    "    'acting', 'voiceacting', 'va', 'ost', 'bgm'\n",
    "]\n",
    "\n",
    "# 2. Define the Function\n",
    "def get_department(text):\n",
    "    # Ensure text is string (just in case)\n",
    "    text = str(text)\n",
    "    \n",
    "    # Priority 1: Engineering\n",
    "    if any(word in text for word in eng_keywords):\n",
    "        return 'Engineering'\n",
    "    \n",
    "    # Priority 2: Design\n",
    "    elif any(word in text for word in design_keywords):\n",
    "        return 'Design'\n",
    "    \n",
    "    # Priority 3: Narrative\n",
    "    elif any(word in text for word in narrative_keywords):\n",
    "        return 'Narrative'\n",
    "    \n",
    "    # If no keywords match, return None (we will drop these rows)\n",
    "    return None\n",
    "\n",
    "# 3. Apply it to create the new column in df_cleaned\n",
    "df_cleaned['department'] = df_cleaned['text_cleaned'].apply(get_department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdf09aff-5f8c-4798-8985-ef6295b7c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kept 25688 labeled reviews out of 33772 (76.1%)\n",
      "label distribution:\n",
      "department\n",
      "Design         15577\n",
      "Engineering     5158\n",
      "Narrative       4953\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[recommend, game, enough, larian, make, master...</td>\n",
       "      <td>Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[game, sit, play, hour, every, save, different...</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, game, hard, figure, cam, thing, first,...</td>\n",
       "      <td>Narrative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apparently, play, game, review, many, game, s...</td>\n",
       "      <td>Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[like, extensive, story, line, character, fun,...</td>\n",
       "      <td>Narrative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_cleaned   department\n",
       "0  [recommend, game, enough, larian, make, master...       Design\n",
       "1  [game, sit, play, hour, every, save, different...  Engineering\n",
       "2  [great, game, hard, figure, cam, thing, first,...    Narrative\n",
       "3  [apparently, play, game, review, many, game, s...       Design\n",
       "4  [like, extensive, story, line, character, fun,...    Narrative"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unlabeled rows\n",
    "before_len = len(df_cleaned)\n",
    "df_final = df_cleaned.dropna(subset=['department']).copy()\n",
    "print(f\"kept {len(df_final)} labeled reviews out of {before_len} ({len(df_final)/before_len:.1%})\")\n",
    "\n",
    "# Show the distribution\n",
    "print(\"label distribution:\")\n",
    "print(df_final['department'].value_counts())\n",
    "df_final[['text_cleaned', 'department']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}