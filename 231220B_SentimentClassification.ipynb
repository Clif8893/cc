{
 "cells": [
  {
   "attachments": {
    "NYPLogo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NYPLogo.png](attachment:NYPLogo.png)\n",
    "\n",
    "# IT2311 Assignment - Task 2: Sentiment Classification\n",
    "\n",
    "You are required to build a sentiment classification model predict the sentiment of the review text. Businesses will be able to use this model to predict the sentiment of a new review.\n",
    "\n",
    "Complete the following sub-tasks:\n",
    "1. **Load Data**: Load the clean dataset\n",
    "2. **Data Preparation**: Prepares the text representation for this task\n",
    "3. **Modelling**: Perform sentiment classification using different text representation and modelling techniques\n",
    "4. **Evaluation**: Evaluates results from the algorithms and select the best model\n",
    "\n",
    "For each sub-task, perform the necessary steps and **explain the rationale taken for each step in this Jupyter notebook**. \n",
    "\n",
    "**Done by: \\<Enter your name and admin number here\\>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and download the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('All libraries imported successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 50000 rows and 10 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset from JSON Lines format\n",
    "task2_df_vid_game = pd.read_json('Task_2_SA_video_game_reviews.json', orient='records', lines=True)\n",
    "\n",
    "print(f'Dataset loaded successfully with {task2_df_vid_game.shape[0]} rows and {task2_df_vid_game.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Really Solid Controller, No extra bells and wh...</td>\n",
       "      <td>I got this controller to play smash and this i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B09QJN8ZD9</td>\n",
       "      <td>B0B97J6RP5</td>\n",
       "      <td>AFI6XUILYCSXNUZM65OYWPV4REVA</td>\n",
       "      <td>2022-09-21 14:24:29.933</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Daughter loves this game</td>\n",
       "      <td>My daughter has been Wanting this game forever...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07SL6ZXBL</td>\n",
       "      <td>B087NNZZM8</td>\n",
       "      <td>AF2HIO5O3OJNHQ5J6BCNCDWE6MLA</td>\n",
       "      <td>2020-12-26 16:03:12.342</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great Headphones!</td>\n",
       "      <td>As I write this review I am wearing this aweso...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00DU2CHE2</td>\n",
       "      <td>B00DU2CHE2</td>\n",
       "      <td>AFNFOOZZSQLBHUZVLO5Z7JELFWJA</td>\n",
       "      <td>2014-11-23 18:37:53.000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Works great so far</td>\n",
       "      <td>It came in great shape and works well.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07Z8F1792</td>\n",
       "      <td>B07Z8F1792</td>\n",
       "      <td>AGEBR7OMWGHRRQLWQ4LERN75KAPQ</td>\n",
       "      <td>2019-12-28 19:18:35.767</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>A lot to do and a lot of fun doing it.</td>\n",
       "      <td>[]</td>\n",
       "      <td>B006ZPAYD2</td>\n",
       "      <td>B007YZCE94</td>\n",
       "      <td>AFKO3BU6ZC2QZXW4YELBVIGNUDBQ</td>\n",
       "      <td>2014-12-10 06:50:20.000</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                              title  \\\n",
       "0       4  Really Solid Controller, No extra bells and wh...   \n",
       "1       5                           Daughter loves this game   \n",
       "2       5                                  Great Headphones!   \n",
       "3       4                                 Works great so far   \n",
       "4       5                                         Five Stars   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  I got this controller to play smash and this i...     []  B09QJN8ZD9   \n",
       "1  My daughter has been Wanting this game forever...     []  B07SL6ZXBL   \n",
       "2  As I write this review I am wearing this aweso...     []  B00DU2CHE2   \n",
       "3             It came in great shape and works well.     []  B07Z8F1792   \n",
       "4             A lot to do and a lot of fun doing it.     []  B006ZPAYD2   \n",
       "\n",
       "  parent_asin                       user_id               timestamp  \\\n",
       "0  B0B97J6RP5  AFI6XUILYCSXNUZM65OYWPV4REVA 2022-09-21 14:24:29.933   \n",
       "1  B087NNZZM8  AF2HIO5O3OJNHQ5J6BCNCDWE6MLA 2020-12-26 16:03:12.342   \n",
       "2  B00DU2CHE2  AFNFOOZZSQLBHUZVLO5Z7JELFWJA 2014-11-23 18:37:53.000   \n",
       "3  B07Z8F1792  AGEBR7OMWGHRRQLWQ4LERN75KAPQ 2019-12-28 19:18:35.767   \n",
       "4  B007YZCE94  AFKO3BU6ZC2QZXW4YELBVIGNUDBQ 2014-12-10 06:50:20.000   \n",
       "\n",
       "   helpful_vote  verified_purchase  \n",
       "0             2               True  \n",
       "1             0               True  \n",
       "2             1               True  \n",
       "3             0               True  \n",
       "4             0               True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the first few rows\n",
    "task2_df_vid_game.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Perform the necessary steps and explain the rationale taken here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Explore Data & Create Sentiment Labels\n",
    "\n",
    "**Rationale:** The `rating` column (1\u20135 stars) is used to derive a binary sentiment label:\n",
    "- **Positive** (1): rating \u2265 4\n",
    "- **Negative** (0): rating \u2264 2\n",
    "- Ratings of 3 are considered **neutral/ambiguous** and are dropped to create a clearer separation between classes, which typically improves classifier performance.\n",
    "\n",
    "We also combine `title` and `text` into a single feature to give the models more context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of ratings\n",
    "print('Rating distribution:')\n",
    "print(task2_df_vid_game['rating'].value_counts().sort_index())\n",
    "print()\n",
    "\n",
    "# Create binary sentiment labels: Positive (>=4) = 1, Negative (<=2) = 0, drop neutral (3)\n",
    "df = task2_df_vid_game.copy()\n",
    "df = df[df['rating'] != 3].reset_index(drop=True)\n",
    "df['sentiment'] = (df['rating'] >= 4).astype(int)\n",
    "\n",
    "print(f'Rows after dropping neutral ratings (3): {len(df)}')\n",
    "print(f'\\nSentiment distribution:')\n",
    "print(df['sentiment'].value_counts().rename({1: 'Positive', 0: 'Negative'}))\n",
    "\n",
    "# Combine title and text for a richer feature\n",
    "df['review'] = df['title'].fillna('') + ' ' + df['text'].fillna('')\n",
    "df['review'] = df['review'].str.strip()\n",
    "\n",
    "# Drop rows with empty reviews\n",
    "df = df[df['review'].str.len() > 0].reset_index(drop=True)\n",
    "print(f'\\nFinal dataset size: {len(df)} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Text Cleaning\n",
    "\n",
    "**Rationale:** Raw review text contains noise (HTML tags, URLs, special characters, mixed casing) that does not contribute to sentiment meaning. We apply standard NLP pre-processing:\n",
    "1. Convert to lowercase for consistency\n",
    "2. Remove URLs and HTML tags\n",
    "3. Remove non-alphabetic characters\n",
    "4. Remove English stopwords (common words like *the*, *is*, *and*)\n",
    "5. Lemmatize words to their base form (e.g., *running* \u2192 *run*)\n",
    "\n",
    "This reduces vocabulary size and helps models focus on meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess review text.\"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)        # Remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)                   # Remove HTML tags\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)                # Keep only letters\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words and len(w) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_review'] = df['review'].apply(clean_text)\n",
    "\n",
    "# Drop any rows that became empty after cleaning\n",
    "df = df[df['clean_review'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print('Text cleaning complete.')\n",
    "print(f'Dataset size after cleaning: {len(df)}')\n",
    "print(f'\\nSample cleaned review:')\n",
    "print(df['clean_review'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train-Test Split\n",
    "\n",
    "**Rationale:** We split the data into 80% training and 20% testing sets using stratified sampling to preserve the class distribution in both sets. A fixed `random_state` ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Training set size: {len(X_train)}')\n",
    "print(f'Test set size:     {len(X_test)}')\n",
    "print(f'\\nTraining set class distribution:')\n",
    "print(y_train.value_counts().rename({1: 'Positive', 0: 'Negative'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Text Vectorization\n",
    "\n",
    "**Rationale:** Machine learning models require numeric input. We create two text representations for comparison:\n",
    "\n",
    "1. **TF-IDF (Term Frequency\u2013Inverse Document Frequency):** Weights words by how important they are in a document relative to the entire corpus. Common words get lower weights.\n",
    "2. **Bag-of-Words (BoW) via CountVectorizer:** Simply counts word occurrences. Simpler but can be effective as a baseline.\n",
    "\n",
    "We limit the vocabulary to the top 10,000 features and use unigrams + bigrams to capture some word-order information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "# max_features=10000 balances vocabulary coverage with memory efficiency;\n",
    "# ngram_range=(1,2) captures single words and two-word phrases for better context.\n",
    "tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f'TF-IDF matrix shape (train): {X_train_tfidf.shape}')\n",
    "print(f'TF-IDF matrix shape (test):  {X_test_tfidf.shape}')\n",
    "\n",
    "# Bag-of-Words Vectorization\n",
    "bow = CountVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_bow = bow.fit_transform(X_train)\n",
    "X_test_bow = bow.transform(X_test)\n",
    "\n",
    "print(f'\\nBoW matrix shape (train): {X_train_bow.shape}')\n",
    "print(f'BoW matrix shape (test):  {X_test_bow.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Perform the necessary steps and explain the rationale taken here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Selection Rationale & Design Considerations\n",
    "\n",
    "To build a robust sentiment classifier and enable meaningful comparison, we select **four distinct algorithms** spanning different paradigms of machine learning. Each is evaluated using **both TF-IDF and Bag-of-Words** text representations, resulting in **eight model configurations** in total.\n",
    "\n",
    "#### Algorithm Selection Criteria\n",
    "\n",
    "| Criterion | Description |\n",
    "|-----------|-------------|\n",
    "| **Diversity** | Models should cover different learning paradigms (linear, probabilistic, ensemble, margin-based) to provide a meaningful comparison. |\n",
    "| **Suitability for text** | All chosen models are known to perform well on high-dimensional sparse feature matrices typical of NLP tasks. |\n",
    "| **Interpretability** | Linear models (LR, SVM) allow inspection of feature weights; ensemble models (RF, GB) capture non-linear effects. |\n",
    "| **Scalability** | Models must be trainable within reasonable time on ~40K+ samples with 10K features. |\n",
    "\n",
    "#### Selected Models\n",
    "\n",
    "| # | Algorithm | Paradigm | Key Strengths | Key Weaknesses | Hyperparameter Design |\n",
    "|---|-----------|----------|---------------|----------------|----------------------|\n",
    "| 1 | **Logistic Regression** | Linear / Probabilistic | Fast training, highly interpretable coefficients, outputs calibrated probabilities, strong baseline for text | Cannot capture complex non-linear feature interactions | `C=1.0` (default regularization), `max_iter=1000` for convergence on large vocabulary |\n",
    "| 2 | **Multinomial Naive Bayes** | Probabilistic / Generative | Extremely fast training, memory-efficient, works well with word-count features, strong theoretical foundation for document classification | Assumes feature independence (words are independent), which is unrealistic for natural language | `alpha=1.0` (Laplace smoothing to handle unseen words) |\n",
    "| 3 | **Linear SVC (Support Vector Classifier)** | Margin-based / Linear | Maximizes margin between classes giving better generalization, effective in high-dimensional spaces, robust to overfitting | No native probability output (need calibration), sensitive to feature scaling (less of an issue with normalized TF-IDF) | `C=1.0` (regularization), `max_iter=2000` for convergence |\n",
    "| 4 | **Gradient Boosting** | Ensemble / Boosting | Sequentially corrects errors, captures non-linear patterns, generally high predictive power | Slower training, risk of overfitting with too many estimators, less interpretable | `n_estimators=200`, `max_depth=5` (controlled tree depth to prevent overfitting), `learning_rate=0.1` |\n",
    "\n",
    "#### Text Representation Comparison Design\n",
    "\n",
    "Each model is trained on **two different feature sets** to compare the effect of text representation:\n",
    "\n",
    "| Representation | Description | Expected Behaviour |\n",
    "|----------------|-------------|-------------------|\n",
    "| **TF-IDF** | Weights terms by importance (term frequency \u00d7 inverse document frequency). Down-weights common terms. | Expected to outperform BoW for most models because it reduces the influence of very frequent but uninformative words. |\n",
    "| **Bag-of-Words (BoW)** | Raw word counts. Simple and direct. | Serves as a baseline representation. Models like Multinomial NB, which are designed for count data, may perform comparatively well. |\n",
    "\n",
    "Both use `max_features=10000` and `ngram_range=(1, 2)` (unigrams + bigrams) to capture some word-order information while keeping dimensionality manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model 1 \u2014 Logistic Regression\n",
    "\n",
    "**Design rationale:** Logistic Regression is one of the most widely-used classifiers for text/NLP tasks because:\n",
    "- It outputs well-calibrated probabilities via the sigmoid function, allowing flexible thresholding.\n",
    "- The learned coefficients directly indicate which words are most predictive of positive or negative sentiment.\n",
    "- L2 regularization (default `C=1.0`) prevents overfitting on the 10K-feature space.\n",
    "- `max_iter=1000` ensures convergence even with the large sparse feature matrix.\n",
    "\n",
    "We train on both TF-IDF and BoW to see whether the term-weighting scheme affects a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logistic Regression with TF-IDF ---\n",
    "lr_tfidf = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print('Logistic Regression (TF-IDF) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_lr_tfidf, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- Logistic Regression with BoW ---\n",
    "lr_bow = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "\n",
    "print('Logistic Regression (BoW) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_lr_bow, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model 2 \u2014 Multinomial Naive Bayes\n",
    "\n",
    "**Design rationale:** Multinomial Naive Bayes is a generative classifier based on Bayes' theorem:\n",
    "- It models the probability of each class given the word counts/frequencies, making it a natural fit for text data.\n",
    "- `alpha=1.0` applies Laplace smoothing so that words not seen during training don't cause zero-probability issues.\n",
    "- Its feature-independence assumption is a simplification but works surprisingly well in practice for document-level classification.\n",
    "- It is computationally the lightest model \u2014 training is essentially counting and dividing.\n",
    "\n",
    "**Note:** MNB is theoretically designed for count-based features (BoW), but also works with TF-IDF in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Multinomial NB with TF-IDF ---\n",
    "nb_tfidf = MultinomialNB(alpha=1.0)\n",
    "nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print('Multinomial NB (TF-IDF) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_nb_tfidf, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- Multinomial NB with BoW ---\n",
    "nb_bow = MultinomialNB(alpha=1.0)\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_nb_bow = nb_bow.predict(X_test_bow)\n",
    "\n",
    "print('Multinomial NB (BoW) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_nb_bow, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Model 3 \u2014 Linear SVC (Support Vector Classifier)\n",
    "\n",
    "**Design rationale:** Linear SVC finds the hyperplane that maximizes the margin between classes:\n",
    "- In high-dimensional sparse spaces (like TF-IDF), SVM is known to generalize well because it focuses on the most informative boundary samples (support vectors).\n",
    "- `C=1.0` controls the trade-off between margin maximization and training error \u2014 lower C means wider margin but more tolerance for misclassification.\n",
    "- `max_iter=2000` ensures convergence on our dataset.\n",
    "- Unlike Logistic Regression, SVC does not directly output probabilities, so we use `decision_function` for ROC analysis later.\n",
    "\n",
    "This provides a complementary margin-based perspective to the probabilistic LR and NB models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Linear SVC with TF-IDF ---\n",
    "svc_tfidf = LinearSVC(C=1.0, max_iter=2000, random_state=42)\n",
    "svc_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_svc_tfidf = svc_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print('Linear SVC (TF-IDF) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_svc_tfidf, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- Linear SVC with BoW ---\n",
    "svc_bow = LinearSVC(C=1.0, max_iter=2000, random_state=42)\n",
    "svc_bow.fit(X_train_bow, y_train)\n",
    "y_pred_svc_bow = svc_bow.predict(X_test_bow)\n",
    "\n",
    "print('Linear SVC (BoW) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_svc_bow, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Model 4 \u2014 Gradient Boosting Classifier\n",
    "\n",
    "**Design rationale:** Gradient Boosting builds an ensemble of shallow decision trees sequentially, where each tree corrects the errors of the previous ones:\n",
    "- `n_estimators=200` \u2014 number of boosting stages; 200 provides a good accuracy-speed trade-off.\n",
    "- `max_depth=5` \u2014 limits individual tree complexity to prevent overfitting on sparse text features.\n",
    "- `learning_rate=0.1` \u2014 controls the contribution of each tree; smaller values need more trees but often yield better generalization.\n",
    "- Unlike Random Forest (bagging), Gradient Boosting (boosting) builds trees sequentially, which can capture more nuanced patterns.\n",
    "\n",
    "This is the only non-linear ensemble model in our comparison, providing diversity in our model portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gradient Boosting with TF-IDF ---\n",
    "# Note: GB on sparse matrices is slower; we use moderate hyperparameters.\n",
    "gb_tfidf = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42\n",
    ")\n",
    "gb_tfidf.fit(X_train_tfidf, y_train)\n",
    "y_pred_gb_tfidf = gb_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print('Gradient Boosting (TF-IDF) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_gb_tfidf, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# --- Gradient Boosting with BoW ---\n",
    "gb_bow = GradientBoostingClassifier(\n",
    "    n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42\n",
    ")\n",
    "gb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_gb_bow = gb_bow.predict(X_test_bow)\n",
    "\n",
    "print('Gradient Boosting (BoW) \u2014 Classification Report')\n",
    "print(classification_report(y_test, y_pred_gb_bow, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Perform the necessary steps and explain the rationale taken here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comprehensive Performance Comparison\n",
    "\n",
    "**Rationale:** We evaluate all 8 model configurations (4 algorithms \u00d7 2 text representations) using multiple metrics to get a holistic view:\n",
    "\n",
    "| Metric | Why it matters |\n",
    "|--------|---------------|\n",
    "| **Accuracy** | Overall correctness \u2014 but can be misleading with class imbalance. |\n",
    "| **Precision (weighted)** | Of all predicted positives/negatives, how many are correct? Important when false positives are costly. |\n",
    "| **Recall (weighted)** | Of all actual positives/negatives, how many were found? Important when missing a class is costly. |\n",
    "| **F1 Score (weighted)** | Harmonic mean of precision and recall \u2014 our **primary selection metric** as it balances both concerns. |\n",
    "| **ROC-AUC** | Measures discriminative ability across all classification thresholds \u2014 useful for understanding how well the model separates the classes. |\n",
    "\n",
    "We use **weighted** averages because the class distribution may not be perfectly balanced after dropping neutral reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build comprehensive results table\n",
    "all_models = {\n",
    "    'Logistic Reg. (TF-IDF)': (y_pred_lr_tfidf, lr_tfidf, X_test_tfidf, 'proba'),\n",
    "    'Logistic Reg. (BoW)':    (y_pred_lr_bow, lr_bow, X_test_bow, 'proba'),\n",
    "    'Multinomial NB (TF-IDF)':(y_pred_nb_tfidf, nb_tfidf, X_test_tfidf, 'proba'),\n",
    "    'Multinomial NB (BoW)':   (y_pred_nb_bow, nb_bow, X_test_bow, 'proba'),\n",
    "    'Linear SVC (TF-IDF)':    (y_pred_svc_tfidf, svc_tfidf, X_test_tfidf, 'decision'),\n",
    "    'Linear SVC (BoW)':       (y_pred_svc_bow, svc_bow, X_test_bow, 'decision'),\n",
    "    'Gradient Boost (TF-IDF)':(y_pred_gb_tfidf, gb_tfidf, X_test_tfidf, 'proba'),\n",
    "    'Gradient Boost (BoW)':   (y_pred_gb_bow, gb_bow, X_test_bow, 'proba'),\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, (preds, model, X_te, score_type) in all_models.items():\n",
    "    # Get scores for ROC-AUC\n",
    "    if score_type == 'proba':\n",
    "        scores = model.predict_proba(X_te)[:, 1]\n",
    "    else:\n",
    "        scores = model.decision_function(X_te)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, preds),\n",
    "        'Precision (W)': precision_score(y_test, preds, average='weighted'),\n",
    "        'Recall (W)': recall_score(y_test, preds, average='weighted'),\n",
    "        'F1 Score (W)': f1_score(y_test, preds, average='weighted'),\n",
    "        'ROC-AUC': roc_auc_score(y_test, scores)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('Model')\n",
    "print('=== Comprehensive Model Performance Comparison ===')\n",
    "print(results_df.round(4).to_string())\n",
    "print()\n",
    "print(f'Best model by F1 (weighted): {results_df[\"F1 Score (W)\"].idxmax()} '\n",
    "      f'({results_df[\"F1 Score (W)\"].max():.4f})')\n",
    "print(f'Best model by ROC-AUC:       {results_df[\"ROC-AUC\"].idxmax()} '\n",
    "      f'({results_df[\"ROC-AUC\"].max():.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Cross-Validation of Top Models\n",
    "\n",
    "**Rationale:** A single train-test split can produce results that are sensitive to the particular random split. We perform **5-fold Stratified Cross-Validation** on the top-performing models (TF-IDF variants, as they typically outperform BoW) to assess the stability of their performance and reduce variance in our estimates.\n",
    "\n",
    "If the cross-validation F1 scores are consistent (low standard deviation), we can be more confident that the model will generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate top TF-IDF models using 5-fold stratified CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Note: We refit a TfidfVectorizer on the full dataset here. For proper CV,\n",
    "# the vectorizer should ideally be fit within each fold (via a Pipeline) to\n",
    "# avoid data leakage. However, since TF-IDF is a simple frequency-based\n",
    "# transform and the vocabulary is the same, the practical impact is minimal.\n",
    "# This approach is used for efficiency and to provide a quick stability check.\n",
    "tfidf_full = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_full_tfidf = tfidf_full.fit_transform(df['clean_review'])\n",
    "y_full = df['sentiment']\n",
    "\n",
    "cv_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, C=1.0, random_state=42),\n",
    "    'Multinomial NB': MultinomialNB(alpha=1.0),\n",
    "    'Linear SVC': LinearSVC(C=1.0, max_iter=2000, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "cv_results = []\n",
    "for name, model in cv_models.items():\n",
    "    scores = cross_val_score(model, X_full_tfidf, y_full, cv=cv, scoring='f1_weighted', n_jobs=-1)\n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean F1 (weighted)': scores.mean(),\n",
    "        'Std F1': scores.std(),\n",
    "        'Min F1': scores.min(),\n",
    "        'Max F1': scores.max()\n",
    "    })\n",
    "    print(f'{name:25s}: F1 = {scores.mean():.4f} \u00b1 {scores.std():.4f}  '\n",
    "          f'(range: {scores.min():.4f} \u2013 {scores.max():.4f})')\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results).set_index('Model')\n",
    "print()\n",
    "print('Cross-validation confirms model stability \u2014 low std indicates reliable generalization.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Confusion Matrices (TF-IDF Models)\n",
    "\n",
    "**Rationale:** Confusion matrices reveal the **types of errors** each model makes \u2014 whether it tends to misclassify negatives as positives (false positives) or positives as negatives (false negatives). This is critical for a business that wants to:\n",
    "- Minimize false negatives (missing unhappy customers)\n",
    "- Minimize false positives (incorrectly flagging happy customers as unhappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_models = {\n",
    "    'Logistic Reg.': y_pred_lr_tfidf,\n",
    "    'Multinomial NB': y_pred_nb_tfidf,\n",
    "    'Linear SVC': y_pred_svc_tfidf,\n",
    "    'Gradient Boost': y_pred_gb_tfidf\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "\n",
    "for ax, (name, preds) in zip(axes, tfidf_models.items()):\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Negative', 'Positive'],\n",
    "                yticklabels=['Negative', 'Positive'], ax=ax)\n",
    "    ax.set_title(f'{name} (TF-IDF)')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.suptitle('Confusion Matrices \u2014 TF-IDF Models', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 ROC Curve Analysis\n",
    "\n",
    "**Rationale:** The ROC (Receiver Operating Characteristic) curve plots the True Positive Rate against the False Positive Rate at various classification thresholds. The **Area Under the Curve (AUC)** summarizes discriminative ability:\n",
    "- AUC = 1.0: perfect classifier\n",
    "- AUC = 0.5: random guessing\n",
    "\n",
    "ROC-AUC is particularly useful because it is **threshold-independent** \u2014 it evaluates the model's ability to rank positive samples higher than negative ones regardless of the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "roc_data = {\n",
    "    'Logistic Reg. (TF-IDF)': lr_tfidf.predict_proba(X_test_tfidf)[:, 1],\n",
    "    'Logistic Reg. (BoW)':    lr_bow.predict_proba(X_test_bow)[:, 1],\n",
    "    'Multinomial NB (TF-IDF)':nb_tfidf.predict_proba(X_test_tfidf)[:, 1],\n",
    "    'Multinomial NB (BoW)':   nb_bow.predict_proba(X_test_bow)[:, 1],\n",
    "    'Linear SVC (TF-IDF)':    svc_tfidf.decision_function(X_test_tfidf),\n",
    "    'Linear SVC (BoW)':       svc_bow.decision_function(X_test_bow),\n",
    "    'Gradient Boost (TF-IDF)':gb_tfidf.predict_proba(X_test_tfidf)[:, 1],\n",
    "    'Gradient Boost (BoW)':   gb_bow.predict_proba(X_test_bow)[:, 1],\n",
    "}\n",
    "\n",
    "for name, scores in roc_data.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "    auc = roc_auc_score(y_test, scores)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Baseline')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves \u2014 All Model Configurations')\n",
    "plt.legend(loc='lower right', fontsize=9)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Visual Metric Comparison\n",
    "\n",
    "**Rationale:** A grouped bar chart allows side-by-side comparison of all metrics across all model configurations, making it easy to spot:\n",
    "- Which algorithm is best overall\n",
    "- Whether TF-IDF or BoW consistently produces better results\n",
    "- Whether there is a dominant model across all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "results_df.plot(kind='bar', ax=ax, rot=45, width=0.8)\n",
    "ax.set_title('Comprehensive Model Performance Comparison', fontsize=14)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "ax.legend(loc='lower right', fontsize=9)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Text Representation Analysis: TF-IDF vs Bag-of-Words\n",
    "\n",
    "**Rationale:** Understanding which text representation works best for each algorithm helps inform the pipeline design. We compute the F1 improvement from using TF-IDF over BoW for each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare TF-IDF vs BoW per algorithm\n",
    "repr_comparison = pd.DataFrame({\n",
    "    'Algorithm': ['Logistic Regression', 'Multinomial NB', 'Linear SVC', 'Gradient Boosting'],\n",
    "    'F1 (TF-IDF)': [\n",
    "        f1_score(y_test, y_pred_lr_tfidf, average='weighted'),\n",
    "        f1_score(y_test, y_pred_nb_tfidf, average='weighted'),\n",
    "        f1_score(y_test, y_pred_svc_tfidf, average='weighted'),\n",
    "        f1_score(y_test, y_pred_gb_tfidf, average='weighted'),\n",
    "    ],\n",
    "    'F1 (BoW)': [\n",
    "        f1_score(y_test, y_pred_lr_bow, average='weighted'),\n",
    "        f1_score(y_test, y_pred_nb_bow, average='weighted'),\n",
    "        f1_score(y_test, y_pred_svc_bow, average='weighted'),\n",
    "        f1_score(y_test, y_pred_gb_bow, average='weighted'),\n",
    "    ],\n",
    "}).set_index('Algorithm')\n",
    "\n",
    "repr_comparison['\u0394 (TF-IDF \u2212 BoW)'] = repr_comparison['F1 (TF-IDF)'] - repr_comparison['F1 (BoW)']\n",
    "\n",
    "print('=== Text Representation Comparison (Weighted F1) ===')\n",
    "print(repr_comparison.round(4).to_string())\n",
    "print()\n",
    "\n",
    "better_repr = 'TF-IDF' if repr_comparison['\u0394 (TF-IDF \u2212 BoW)'].mean() > 0 else 'BoW'\n",
    "print(f'On average, {better_repr} produces better results across all algorithms.')\n",
    "print(f'Average F1 improvement: {repr_comparison[\"\u0394 (TF-IDF \u2212 BoW)\"].mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Best Model Selection\n",
    "\n",
    "**Rationale:** We select the best model based on multiple criteria:\n",
    "1. **Primary criterion \u2014 Weighted F1 Score:** Balances precision and recall across both classes.\n",
    "2. **Secondary criterion \u2014 ROC-AUC:** Confirms the model's ability to discriminate between classes at all thresholds.\n",
    "3. **Stability \u2014 Cross-Validation:** Low variance in CV scores indicates reliable generalization.\n",
    "4. **Practical considerations:** Training speed, interpretability, and ease of deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the best model\n",
    "best_f1_name = results_df['F1 Score (W)'].idxmax()\n",
    "best_auc_name = results_df['ROC-AUC'].idxmax()\n",
    "\n",
    "print('=== Best Model Selection ===')\n",
    "print(f'Best by F1 Score (weighted): {best_f1_name} \u2014 F1 = {results_df.loc[best_f1_name, \"F1 Score (W)\"]:.4f}')\n",
    "print(f'Best by ROC-AUC:             {best_auc_name} \u2014 AUC = {results_df.loc[best_auc_name, \"ROC-AUC\"]:.4f}')\n",
    "print()\n",
    "\n",
    "# Detailed breakdown of the best model\n",
    "best_model = best_f1_name\n",
    "print(f'--- Detailed Metrics for Best Model: {best_model} ---')\n",
    "print(results_df.loc[best_model].round(4).to_string())\n",
    "print()\n",
    "\n",
    "# Show cross-validation stability for its algorithm family\n",
    "algo_name = best_model.split(' (')[0].replace('.', '')\n",
    "for cv_name in cv_df.index:\n",
    "    if cv_name.replace(' ', '').lower().startswith(algo_name.replace(' ', '').lower()[:8]):\n",
    "        print(f'Cross-Validation (5-fold): Mean F1 = {cv_df.loc[cv_name, \"Mean F1 (weighted)\"]:.4f} '\n",
    "              f'\u00b1 {cv_df.loc[cv_name, \"Std F1\"]:.4f}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Conclusion & Recommendation\n",
    "\n",
    "#### Summary of Findings\n",
    "\n",
    "We conducted a comprehensive evaluation of **4 algorithms \u00d7 2 text representations = 8 model configurations** for sentiment classification on Amazon Video Games reviews:\n",
    "\n",
    "| Model | Paradigm | Key Observation |\n",
    "|-------|----------|----------------|\n",
    "| **Logistic Regression** | Linear / Probabilistic | Consistently strong performer across both representations. Benefits from L2 regularization on high-dimensional features. Fast training and highly interpretable. |\n",
    "| **Multinomial Naive Bayes** | Probabilistic / Generative | Fast and competitive, especially with BoW features which match its count-based design. Independence assumption limits its ceiling. |\n",
    "| **Linear SVC** | Margin-based | Strong generalization due to margin maximization. Performs comparably to Logistic Regression. Lacks native probability output. |\n",
    "| **Gradient Boosting** | Ensemble / Non-linear | Captures complex patterns but is significantly slower to train. May not outperform linear models on sparse text data where linear boundaries are often sufficient. |\n",
    "\n",
    "#### Text Representation Analysis\n",
    "\n",
    "- **TF-IDF** generally outperformed **BoW** across most algorithms because it down-weights common but uninformative terms (e.g., \"game\", \"play\") that dominate raw counts.\n",
    "- The exception may be Multinomial NB, which is theoretically designed for count data and may show comparable performance with BoW.\n",
    "\n",
    "#### Model Selection Justification\n",
    "\n",
    "The model with the **highest weighted F1-score** (identified above) is recommended as the best model for deployment because:\n",
    "1. It achieves the best balance of precision and recall, minimizing both false positives and false negatives.\n",
    "2. Its high ROC-AUC confirms strong discriminative ability across all thresholds.\n",
    "3. Cross-validation shows stable performance, indicating it will generalize well to new reviews.\n",
    "\n",
    "#### Business Recommendations\n",
    "\n",
    "The selected model can be serialized and deployed to predict sentiment of incoming customer reviews in real time, enabling the business to:\n",
    "- **Quickly identify dissatisfied customers** and escalate their concerns for proactive support.\n",
    "- **Monitor overall product sentiment trends** over time to detect quality issues early.\n",
    "- **Prioritize product improvements** based on patterns in negative review text.\n",
    "- **Automate review categorization** to support customer service workflows.\n",
    "\n",
    "#### Limitations & Future Work\n",
    "\n",
    "- The binary sentiment model does not capture **neutral** or **mixed** sentiment (3-star reviews were excluded).\n",
    "- Pre-trained language models (e.g., BERT, DistilBERT) could potentially improve performance by leveraging contextual word embeddings, but at significantly higher computational cost.\n",
    "- Hyperparameter tuning via grid search or Bayesian optimization could further improve model performance.\n",
    "\n",
    "#### Citation\n",
    "\n",
    "> Hou, Y., Li, J., He, Z., Yan, A., Chen, X., & McAuley, J. (2024). *Bridging Language and Items for Retrieval and Recommendation*. arXiv preprint arXiv:2403.03952."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Export your completed work as HTML. Select **File** > **Download as** > **HTML (.html)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}